{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The math\n",
    "$y = Xb$ where $y$ are predictions, $X$ are features and $b$ are trained model parameters\n",
    "\n",
    "For MSE we have closed form solution($\\hat{y}$ as labels):\n",
    "$\n",
    "b=(X^TX)^{-1}X^T \\hat{y}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "n = 10 # 10 data\n",
    "k = 5 # num of feautres\n",
    "\n",
    "features = np.random.randn(n, k)\n",
    "labels = np.random.randn(n, 1)\n",
    "\n",
    "X = features\n",
    "y_hat = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LR with closed form**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.56149848]\n",
      " [-1.09514572]\n",
      " [ 0.30861099]\n",
      " [-0.85188994]\n",
      " [ 0.30270015]]\n",
      "[0.20643985]\n"
     ]
    }
   ],
   "source": [
    "b_closed_form = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y_hat)\n",
    "print(b)\n",
    "\n",
    "def MSE(y: NDArray, y_pred: NDArray) -> float:\n",
    "    return sum(((y-y_pred) ** 2)/len(y))\n",
    "\n",
    "print(MSE(y_hat, X.dot(b_closed_form)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LR through gradient descent**\n",
    "\n",
    "The math:\n",
    "$\n",
    "L = \\frac{1}{n}\\sum_{i=1}^n(\\hat{y_i}-\\sum_{j=1}^kx_{ij}b_j)^2\n",
    "\\Rightarrow \\frac{\\partial L}{\\partial b_m} = -\\frac{2}{n}\\sum_{i=1}^n x_{im}(\\hat{y_i}-\\sum_{j=1}^kx_{ij}b_j)\n",
    "\\Rightarrow \\frac{\\partial L}{\\partial b} = -\\frac{2}{n} X^T(\\hat{y} - Xb)\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 10, loss [0.42182709]\n",
      "At epoch 20, loss [0.22779113]\n",
      "At epoch 30, loss [0.20916916]\n",
      "At epoch 40, loss [0.20684663]\n",
      "At epoch 50, loss [0.2065084]\n",
      "At epoch 60, loss [0.20645322]\n",
      "At epoch 70, loss [0.20644295]\n",
      "At epoch 80, loss [0.20644069]\n",
      "At epoch 90, loss [0.2064401]\n",
      "At epoch 100, loss [0.20643993]\n",
      "[[ 0.27057739]\n",
      " [-0.38373311]\n",
      " [ 0.46913375]\n",
      " [-0.53526969]\n",
      " [-0.06046746]]\n",
      "[0.20643992]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "max_epochs = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "b_gd = np.random.randn(k, 1)\n",
    "loss = []\n",
    "for i in range(1, max_epochs+1):\n",
    "    pred = X.dot(b_gd)\n",
    "    loss.append(MSE(y_hat, pred))\n",
    "    gradient = -2/n * X.T.dot(y_hat - pred)\n",
    "    b_gd -= learning_rate*gradient\n",
    "\n",
    "    if i%10 == 0:\n",
    "        print(f'At epoch {i}, loss {loss[-1]}')\n",
    "\n",
    "print(b_gd)\n",
    "print(MSE(y_hat, X.dot(b_gd)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
