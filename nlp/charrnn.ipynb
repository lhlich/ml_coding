{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text generation example with char-rnn\n",
    "\n",
    "First to load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def download_text(url):\n",
    "    # Send a HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "url = 'https://homl.info/shakespeare'\n",
    "text_data = download_text(url)\n",
    "if text_data:\n",
    "    print(\"Data downloaded successfully!\")\n",
    "else:\n",
    "    print(\"Failed to download data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Vocab and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o': 2, 'm': 3, 'v': 4, 'u': 5, 'h': 6, \"'\": 7, 't': 8, 'w': 9, 'b': 10, 'p': 11, 'c': 12, '&': 13, '-': 14, ' ': 15, '!': 16, 'j': 17, 'r': 18, 'q': 19, '$': 20, ';': 21, ':': 22, 'e': 23, '?': 24, 's': 25, 'n': 26, 'z': 27, 'i': 28, 'l': 29, 'g': 30, ',': 31, 'y': 32, '3': 33, 'x': 34, 'a': 35, 'd': 36, 'k': 37, '.': 38, 'f': 39, '<UNK>': 1, '<PAD>': 0}\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for char in text_data:\n",
    "    if char != '\\n':\n",
    "        vocab.add(char.lower())\n",
    "\n",
    "vocab_mapping = {char:i+2 for i, char in enumerate(vocab)} # 0 for padding and 1 for unknown\n",
    "vocab_mapping['<UNK>'] = 1\n",
    "vocab_mapping['<PAD>'] = 0\n",
    "print(vocab_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of example data: [torch.Size([2, 100]), torch.Size([2, 100])]\n",
      "(tensor([[39, 28, 18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22, 10, 23, 39,  2,\n",
      "         18, 23, 15,  9, 23, 15, 11, 18,  2, 12, 23, 23, 36, 15, 35, 26, 32, 15,\n",
      "         39,  5, 18,  8,  6, 23, 18, 31, 15,  6, 23, 35, 18, 15,  3, 23, 15, 25,\n",
      "         11, 23, 35, 37, 38, 35, 29, 29, 22, 25, 11, 23, 35, 37, 31, 15, 25, 11,\n",
      "         23, 35, 37, 38, 39, 28, 18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22,\n",
      "         32,  2,  5, 15, 35, 18, 23, 15, 35, 29],\n",
      "        [28, 18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22, 10, 23, 39,  2, 18,\n",
      "         23, 15,  9, 23, 15, 11, 18,  2, 12, 23, 23, 36, 15, 35, 26, 32, 15, 39,\n",
      "          5, 18,  8,  6, 23, 18, 31, 15,  6, 23, 35, 18, 15,  3, 23, 15, 25, 11,\n",
      "         23, 35, 37, 38, 35, 29, 29, 22, 25, 11, 23, 35, 37, 31, 15, 25, 11, 23,\n",
      "         35, 37, 38, 39, 28, 18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22, 32,\n",
      "          2,  5, 15, 35, 18, 23, 15, 35, 29, 29]]), tensor([[28, 18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22, 10, 23, 39,  2, 18,\n",
      "         23, 15,  9, 23, 15, 11, 18,  2, 12, 23, 23, 36, 15, 35, 26, 32, 15, 39,\n",
      "          5, 18,  8,  6, 23, 18, 31, 15,  6, 23, 35, 18, 15,  3, 23, 15, 25, 11,\n",
      "         23, 35, 37, 38, 35, 29, 29, 22, 25, 11, 23, 35, 37, 31, 15, 25, 11, 23,\n",
      "         35, 37, 38, 39, 28, 18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22, 32,\n",
      "          2,  5, 15, 35, 18, 23, 15, 35, 29, 29],\n",
      "        [18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22, 10, 23, 39,  2, 18, 23,\n",
      "         15,  9, 23, 15, 11, 18,  2, 12, 23, 23, 36, 15, 35, 26, 32, 15, 39,  5,\n",
      "         18,  8,  6, 23, 18, 31, 15,  6, 23, 35, 18, 15,  3, 23, 15, 25, 11, 23,\n",
      "         35, 37, 38, 35, 29, 29, 22, 25, 11, 23, 35, 37, 31, 15, 25, 11, 23, 35,\n",
      "         37, 38, 39, 28, 18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22, 32,  2,\n",
      "          5, 15, 35, 18, 23, 15, 35, 29, 29, 15]]))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class TextTransform:\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocab = vocabulary\n",
    "        self.n_tokens = len(vocabulary)\n",
    "        reverse_map = [None] * len(vocabulary)\n",
    "        for k, v in vocabulary.items():\n",
    "            reverse_map[v] = k\n",
    "        self.reverse_map = reverse_map\n",
    "\n",
    "    def __call__(self, text):\n",
    "        # Numericalize tokens\n",
    "        return [self.vocab.get(char.lower(), 1) for char in text]\n",
    "\n",
    "    \n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data: str, transform=None, window_len = 100) -> None:\n",
    "        self.data = data.replace('\\n', '').lower()\n",
    "        self.transform = transform\n",
    "        self.window_len = window_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.window_len -1 # need next few tokens as label\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx:idx+self.window_len]\n",
    "        label = self.data[idx+1:idx+self.window_len+1]\n",
    "        if self.transform:\n",
    "            return self.transform(text), self.transform(label)\n",
    "        else:\n",
    "            return text, label\n",
    "\n",
    "\n",
    "window_len = 100      \n",
    "def collate_self_supervision(batch):\n",
    "    texts, labels = zip(*batch)  # Unzip the tuples into separate lists\n",
    "    texts_tensor = torch.tensor(texts, dtype=torch.long)  # Ensure dtype is long for indices\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)  # Same for labels\n",
    "    return texts_tensor, labels_tensor\n",
    "\n",
    "\n",
    "\n",
    "transform = TextTransform(vocab_mapping)\n",
    "dataset = MyDataset(text_data, transform, window_len)\n",
    "data_loader = DataLoader(dataset, batch_size=2, collate_fn=collate_self_supervision)\n",
    "\n",
    "example_data = data_loader._get_iterator()._next_data()\n",
    "print(f'shapes of example data: {[t.shape for t in example_data]}')\n",
    "print(example_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define your device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, n_tokens, emb_dim=16, GRU_dim=128):\n",
    "        super(CharRNN, self).__init__() \n",
    "        self.embedding = nn.Embedding(n_tokens, emb_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(emb_dim, GRU_dim, batch_first=True)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(GRU_dim, n_tokens),\n",
    "            nn.LogSoftmax(dim=2),\n",
    "        )\n",
    "        self.GRU_dim = GRU_dim\n",
    "    \n",
    "    def forward(self, input):\n",
    "        emb = self.embedding(input)  # [batch, window_len, emb_dim]\n",
    "        seq, _h_n = self.gru(emb)    # [batch, window_len, GRU_dim]\n",
    "        return self.output(seq)       # [batch, window_len, n_tokens]\n",
    "    \n",
    "    def generate(self, input_tensor, length=5):\n",
    "        N = len(input_tensor)\n",
    "        h = torch.zeros(size=(1, N, self.GRU_dim)).to(device)\n",
    "\n",
    "        output = []\n",
    "\n",
    "        for _ in range(length):\n",
    "            if len(output) == 0:\n",
    "                input = input_tensor\n",
    "            else:\n",
    "                input = output[-1].unsqueeze(1)\n",
    "            emb = self.embedding(input)  # [batch, window_len, emb_dim]\n",
    "            seq, h = self.gru(emb, h)    # [batch, window_len, GRU_dim]\n",
    "            log_probs = self.output(seq)       # [batch, window_len, n_tokens]\n",
    "            next_token = torch.argmax(log_probs, dim=2) # # [batch, window_len]\n",
    "            output.append(next_token[:, -1]) # [batch, 1]\n",
    "\n",
    "        return output #[batch, length]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate(prompt: str, model, length=5) -> str:\n",
    "    input_tensor = torch.tensor(transform(prompt)).unsqueeze(0).to(device)\n",
    "    output_tokens = model.generate(input_tensor, length)  # Ensure this is on the right device\n",
    "    # print(output_tokens)\n",
    "    return ''.join([transform.reverse_map[idx] for idx in output_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Before training:\n",
      "    prompt: To be or not to be\n",
      "    next seq: cdc::\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Move model to device\n",
    "model = CharRNN(transform.n_tokens).to(device)\n",
    "prompt = 'To be or not to be'\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Before training:\n",
    "    prompt: {prompt}\n",
    "    next seq: {generate(prompt, model, temperature=0.3)}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch 1 ---\n",
      "0 batches processed(0.0%), ce loss 3.680591106414795\n",
      "1000 batches processed(0.0018599564398201795%), ce loss 2.2073636054992676\n",
      "2000 batches processed(0.003719912879640359%), ce loss 2.2762529850006104\n",
      "3000 batches processed(0.005579869319460538%), ce loss 1.6998295783996582\n",
      "4000 batches processed(0.007439825759280718%), ce loss 1.625838041305542\n",
      "5000 batches processed(0.009299782199100897%), ce loss 1.570011019706726\n",
      "6000 batches processed(0.011159738638921076%), ce loss 1.8524770736694336\n",
      "7000 batches processed(0.013019695078741256%), ce loss 1.5986268520355225\n",
      "8000 batches processed(0.014879651518561436%), ce loss 1.7755731344223022\n",
      "9000 batches processed(0.016739607958381614%), ce loss 1.5524282455444336\n",
      "10000 batches processed(0.018599564398201793%), ce loss 1.3518612384796143\n",
      "11000 batches processed(0.020459520838021973%), ce loss 1.6307848691940308\n",
      "12000 batches processed(0.022319477277842153%), ce loss 1.8313945531845093\n",
      "13000 batches processed(0.024179433717662333%), ce loss 1.7861709594726562\n",
      "14000 batches processed(0.026039390157482512%), ce loss 1.582334041595459\n",
      "15000 batches processed(0.027899346597302692%), ce loss 1.7832591533660889\n",
      "16000 batches processed(0.02975930303712287%), ce loss 1.5395866632461548\n",
      "17000 batches processed(0.03161925947694305%), ce loss 1.3986438512802124\n",
      "18000 batches processed(0.03347921591676323%), ce loss 1.5406484603881836\n",
      "19000 batches processed(0.03533917235658341%), ce loss 1.4201312065124512\n",
      "20000 batches processed(0.03719912879640359%), ce loss 1.4668056964874268\n",
      "21000 batches processed(0.03905908523622377%), ce loss 1.5869439840316772\n",
      "22000 batches processed(0.040919041676043946%), ce loss 1.4069327116012573\n",
      "23000 batches processed(0.04277899811586413%), ce loss 1.432054042816162\n",
      "24000 batches processed(0.044638954555684306%), ce loss 1.7168060541152954\n",
      "25000 batches processed(0.04649891099550448%), ce loss 1.7246670722961426\n",
      "26000 batches processed(0.048358867435324665%), ce loss 1.49945867061615\n",
      "27000 batches processed(0.05021882387514484%), ce loss 1.5615856647491455\n",
      "28000 batches processed(0.052078780314965024%), ce loss 1.5280146598815918\n",
      "29000 batches processed(0.0539387367547852%), ce loss 1.5146578550338745\n",
      "30000 batches processed(0.055798693194605384%), ce loss 1.3411599397659302\n",
      "31000 batches processed(0.05765864963442556%), ce loss 1.4841407537460327\n",
      "32000 batches processed(0.05951860607424574%), ce loss 1.6540231704711914\n",
      "33000 batches processed(0.06137856251406592%), ce loss 1.4406388998031616\n",
      "34000 batches processed(0.0632385189538861%), ce loss 1.59763765335083\n",
      "35000 batches processed(0.06509847539370628%), ce loss 1.6947479248046875\n",
      "36000 batches processed(0.06695843183352646%), ce loss 1.578529715538025\n",
      "37000 batches processed(0.06881838827334665%), ce loss 1.3177963495254517\n",
      "38000 batches processed(0.07067834471316682%), ce loss 1.4312244653701782\n",
      "39000 batches processed(0.072538301152987%), ce loss 1.4149574041366577\n",
      "40000 batches processed(0.07439825759280717%), ce loss 1.5556738376617432\n",
      "41000 batches processed(0.07625821403262735%), ce loss 1.7297335863113403\n",
      "42000 batches processed(0.07811817047244754%), ce loss 1.5664383172988892\n",
      "43000 batches processed(0.07997812691226772%), ce loss 1.4783217906951904\n",
      "44000 batches processed(0.08183808335208789%), ce loss 1.4158129692077637\n",
      "45000 batches processed(0.08369803979190807%), ce loss 1.533666729927063\n",
      "46000 batches processed(0.08555799623172826%), ce loss 1.66074800491333\n",
      "47000 batches processed(0.08741795267154844%), ce loss 1.7364263534545898\n",
      "48000 batches processed(0.08927790911136861%), ce loss 1.5333218574523926\n",
      "49000 batches processed(0.09113786555118879%), ce loss 1.6897152662277222\n",
      "50000 batches processed(0.09299782199100896%), ce loss 1.476845145225525\n",
      "51000 batches processed(0.09485777843082915%), ce loss 1.6458253860473633\n",
      "52000 batches processed(0.09671773487064933%), ce loss 1.372914433479309\n",
      "53000 batches processed(0.0985776913104695%), ce loss 1.3558731079101562\n",
      "54000 batches processed(0.10043764775028968%), ce loss 1.7813972234725952\n",
      "55000 batches processed(0.10229760419010987%), ce loss 1.4545941352844238\n",
      "56000 batches processed(0.10415756062993005%), ce loss 1.6600842475891113\n",
      "57000 batches processed(0.10601751706975023%), ce loss 1.4804012775421143\n",
      "58000 batches processed(0.1078774735095704%), ce loss 1.672717571258545\n",
      "59000 batches processed(0.10973742994939059%), ce loss 1.4515063762664795\n",
      "60000 batches processed(0.11159738638921077%), ce loss 1.6791436672210693\n",
      "61000 batches processed(0.11345734282903094%), ce loss 1.4048651456832886\n",
      "62000 batches processed(0.11531729926885112%), ce loss 1.556583285331726\n",
      "63000 batches processed(0.1171772557086713%), ce loss 1.4740239381790161\n",
      "64000 batches processed(0.11903721214849149%), ce loss 1.4124761819839478\n",
      "65000 batches processed(0.12089716858831166%), ce loss 1.4804141521453857\n",
      "66000 batches processed(0.12275712502813184%), ce loss 1.4647088050842285\n",
      "67000 batches processed(0.12461708146795202%), ce loss 1.458634614944458\n",
      "68000 batches processed(0.1264770379077722%), ce loss 1.4373106956481934\n",
      "69000 batches processed(0.12833699434759238%), ce loss 1.552697777748108\n",
      "70000 batches processed(0.13019695078741256%), ce loss 1.5813262462615967\n",
      "71000 batches processed(0.13205690722723273%), ce loss 1.3187363147735596\n",
      "72000 batches processed(0.1339168636670529%), ce loss 1.4610003232955933\n",
      "73000 batches processed(0.1357768201068731%), ce loss 1.7570968866348267\n",
      "74000 batches processed(0.1376367765466933%), ce loss 1.530545949935913\n",
      "75000 batches processed(0.13949673298651347%), ce loss 1.623051404953003\n",
      "76000 batches processed(0.14135668942633364%), ce loss 1.4269604682922363\n",
      "77000 batches processed(0.14321664586615382%), ce loss 1.4795745611190796\n",
      "78000 batches processed(0.145076602305974%), ce loss 1.3800619840621948\n",
      "79000 batches processed(0.14693655874579417%), ce loss 1.4739669561386108\n",
      "80000 batches processed(0.14879651518561435%), ce loss 1.8120425939559937\n",
      "81000 batches processed(0.15065647162543452%), ce loss 1.3565424680709839\n",
      "82000 batches processed(0.1525164280652547%), ce loss 1.5114312171936035\n",
      "83000 batches processed(0.1543763845050749%), ce loss 1.6286097764968872\n",
      "84000 batches processed(0.15623634094489508%), ce loss 1.5550247430801392\n",
      "85000 batches processed(0.15809629738471526%), ce loss 1.5295495986938477\n",
      "86000 batches processed(0.15995625382453543%), ce loss 1.2448616027832031\n",
      "87000 batches processed(0.1618162102643556%), ce loss 1.326847791671753\n",
      "88000 batches processed(0.16367616670417579%), ce loss 1.3576858043670654\n",
      "89000 batches processed(0.16553612314399596%), ce loss 1.2580909729003906\n",
      "90000 batches processed(0.16739607958381614%), ce loss 1.4333773851394653\n",
      "91000 batches processed(0.1692560360236363%), ce loss 1.4062732458114624\n",
      "92000 batches processed(0.17111599246345652%), ce loss 1.4245414733886719\n",
      "93000 batches processed(0.1729759489032767%), ce loss 1.7183175086975098\n",
      "94000 batches processed(0.17483590534309687%), ce loss 1.6061623096466064\n",
      "95000 batches processed(0.17669586178291705%), ce loss 1.4829946756362915\n",
      "96000 batches processed(0.17855581822273722%), ce loss 1.4091534614562988\n",
      "97000 batches processed(0.1804157746625574%), ce loss 1.6866918802261353\n",
      "98000 batches processed(0.18227573110237758%), ce loss 1.3977835178375244\n",
      "99000 batches processed(0.18413568754219775%), ce loss 1.6550930738449097\n",
      "100000 batches processed(0.18599564398201793%), ce loss 1.4417232275009155\n",
      "101000 batches processed(0.18785560042183813%), ce loss 1.5823076963424683\n",
      "102000 batches processed(0.1897155568616583%), ce loss 1.5759793519973755\n",
      "103000 batches processed(0.19157551330147848%), ce loss 1.55195951461792\n",
      "104000 batches processed(0.19343546974129866%), ce loss 1.127455234527588\n",
      "105000 batches processed(0.19529542618111884%), ce loss 1.5200985670089722\n",
      "106000 batches processed(0.197155382620939%), ce loss 1.4973766803741455\n",
      "107000 batches processed(0.1990153390607592%), ce loss 1.8526321649551392\n",
      "108000 batches processed(0.20087529550057937%), ce loss 1.5533473491668701\n",
      "109000 batches processed(0.20273525194039957%), ce loss 1.3331811428070068\n",
      "110000 batches processed(0.20459520838021975%), ce loss 1.406955361366272\n",
      "111000 batches processed(0.20645516482003992%), ce loss 1.5423896312713623\n",
      "112000 batches processed(0.2083151212598601%), ce loss 1.6618157625198364\n",
      "113000 batches processed(0.21017507769968027%), ce loss 1.568130373954773\n",
      "114000 batches processed(0.21203503413950045%), ce loss 1.6075499057769775\n",
      "115000 batches processed(0.21389499057932063%), ce loss 1.617862343788147\n",
      "116000 batches processed(0.2157549470191408%), ce loss 1.2478270530700684\n",
      "117000 batches processed(0.21761490345896098%), ce loss 1.512141466140747\n",
      "118000 batches processed(0.21947485989878118%), ce loss 1.5030261278152466\n",
      "119000 batches processed(0.22133481633860136%), ce loss 1.4130276441574097\n",
      "120000 batches processed(0.22319477277842154%), ce loss 1.575236201286316\n",
      "121000 batches processed(0.2250547292182417%), ce loss 1.7397788763046265\n",
      "122000 batches processed(0.2269146856580619%), ce loss 1.4513343572616577\n",
      "123000 batches processed(0.22877464209788206%), ce loss 1.4014825820922852\n",
      "124000 batches processed(0.23063459853770224%), ce loss 1.6120843887329102\n",
      "125000 batches processed(0.23249455497752242%), ce loss 1.5118216276168823\n",
      "126000 batches processed(0.2343545114173426%), ce loss 1.4658890962600708\n",
      "127000 batches processed(0.2362144678571628%), ce loss 1.8755221366882324\n",
      "128000 batches processed(0.23807442429698297%), ce loss 1.407639741897583\n",
      "129000 batches processed(0.23993438073680315%), ce loss 1.4268220663070679\n",
      "130000 batches processed(0.24179433717662333%), ce loss 1.3775439262390137\n",
      "131000 batches processed(0.2436542936164435%), ce loss 1.578715205192566\n",
      "132000 batches processed(0.24551425005626368%), ce loss 1.466862440109253\n",
      "133000 batches processed(0.24737420649608385%), ce loss 1.5382094383239746\n",
      "134000 batches processed(0.24923416293590403%), ce loss 1.4648754596710205\n",
      "135000 batches processed(0.25109411937572423%), ce loss 1.3406035900115967\n",
      "136000 batches processed(0.2529540758155444%), ce loss 1.5586607456207275\n",
      "137000 batches processed(0.2548140322553646%), ce loss 1.574874997138977\n",
      "138000 batches processed(0.25667398869518476%), ce loss 1.4461655616760254\n",
      "139000 batches processed(0.25853394513500494%), ce loss 1.217555284500122\n",
      "140000 batches processed(0.2603939015748251%), ce loss 1.378880262374878\n",
      "141000 batches processed(0.2622538580146453%), ce loss 1.354859471321106\n",
      "142000 batches processed(0.26411381445446547%), ce loss 1.4728409051895142\n",
      "143000 batches processed(0.26597377089428564%), ce loss 1.5819213390350342\n",
      "144000 batches processed(0.2678337273341058%), ce loss 1.492544412612915\n",
      "145000 batches processed(0.269693683773926%), ce loss 1.1935718059539795\n",
      "146000 batches processed(0.2715536402137462%), ce loss 1.5572487115859985\n",
      "147000 batches processed(0.27341359665356635%), ce loss 1.4839590787887573\n",
      "148000 batches processed(0.2752735530933866%), ce loss 1.5301425457000732\n",
      "149000 batches processed(0.27713350953320676%), ce loss 1.515016794204712\n",
      "150000 batches processed(0.27899346597302693%), ce loss 1.822291374206543\n",
      "151000 batches processed(0.2808534224128471%), ce loss 1.2968051433563232\n",
      "152000 batches processed(0.2827133788526673%), ce loss 1.3618664741516113\n",
      "153000 batches processed(0.28457333529248746%), ce loss 1.3694350719451904\n",
      "154000 batches processed(0.28643329173230764%), ce loss 1.5239365100860596\n",
      "155000 batches processed(0.2882932481721278%), ce loss 1.540563941001892\n",
      "156000 batches processed(0.290153204611948%), ce loss 1.5650655031204224\n",
      "157000 batches processed(0.29201316105176817%), ce loss 1.4061617851257324\n",
      "158000 batches processed(0.29387311749158834%), ce loss 1.6387884616851807\n",
      "159000 batches processed(0.2957330739314085%), ce loss 1.4935736656188965\n",
      "160000 batches processed(0.2975930303712287%), ce loss 1.4609789848327637\n",
      "161000 batches processed(0.29945298681104887%), ce loss 1.7172824144363403\n",
      "162000 batches processed(0.30131294325086905%), ce loss 1.1624363660812378\n",
      "163000 batches processed(0.3031728996906892%), ce loss 1.6338810920715332\n",
      "164000 batches processed(0.3050328561305094%), ce loss 1.5233458280563354\n",
      "165000 batches processed(0.3068928125703296%), ce loss 1.4964152574539185\n",
      "166000 batches processed(0.3087527690101498%), ce loss 1.2984718084335327\n",
      "167000 batches processed(0.31061272544997%), ce loss 1.612149715423584\n",
      "168000 batches processed(0.31247268188979016%), ce loss 1.6106921434402466\n",
      "169000 batches processed(0.31433263832961034%), ce loss 1.5013192892074585\n",
      "170000 batches processed(0.3161925947694305%), ce loss 1.376912236213684\n",
      "171000 batches processed(0.3180525512092507%), ce loss 1.7866504192352295\n",
      "172000 batches processed(0.31991250764907087%), ce loss 1.3631789684295654\n",
      "173000 batches processed(0.32177246408889104%), ce loss 1.5399713516235352\n",
      "174000 batches processed(0.3236324205287112%), ce loss 1.3844317197799683\n",
      "175000 batches processed(0.3254923769685314%), ce loss 1.5170751810073853\n",
      "176000 batches processed(0.32735233340835157%), ce loss 1.3058007955551147\n",
      "177000 batches processed(0.32921228984817175%), ce loss 1.3724517822265625\n",
      "178000 batches processed(0.3310722462879919%), ce loss 1.5013537406921387\n",
      "179000 batches processed(0.3329322027278121%), ce loss 1.547603964805603\n",
      "180000 batches processed(0.3347921591676323%), ce loss 1.349819302558899\n",
      "181000 batches processed(0.33665211560745245%), ce loss 1.336678147315979\n",
      "182000 batches processed(0.3385120720472726%), ce loss 1.4367492198944092\n",
      "183000 batches processed(0.34037202848709286%), ce loss 1.5392162799835205\n",
      "184000 batches processed(0.34223198492691304%), ce loss 1.445859670639038\n",
      "185000 batches processed(0.3440919413667332%), ce loss 1.2393492460250854\n",
      "186000 batches processed(0.3459518978065534%), ce loss 1.478525996208191\n",
      "187000 batches processed(0.34781185424637356%), ce loss 1.6557766199111938\n",
      "188000 batches processed(0.34967181068619374%), ce loss 1.3862653970718384\n",
      "189000 batches processed(0.3515317671260139%), ce loss 1.4203064441680908\n",
      "190000 batches processed(0.3533917235658341%), ce loss 1.2349786758422852\n",
      "191000 batches processed(0.35525168000565427%), ce loss 1.3557811975479126\n",
      "192000 batches processed(0.35711163644547445%), ce loss 1.4296351671218872\n",
      "193000 batches processed(0.3589715928852946%), ce loss 1.5670422315597534\n",
      "194000 batches processed(0.3608315493251148%), ce loss 1.4095773696899414\n",
      "195000 batches processed(0.362691505764935%), ce loss 1.4001153707504272\n",
      "196000 batches processed(0.36455146220475515%), ce loss 1.3950310945510864\n",
      "197000 batches processed(0.3664114186445753%), ce loss 1.3661315441131592\n",
      "198000 batches processed(0.3682713750843955%), ce loss 1.4073160886764526\n",
      "199000 batches processed(0.3701313315242157%), ce loss 1.6138087511062622\n",
      "200000 batches processed(0.37199128796403585%), ce loss 1.3042410612106323\n",
      "201000 batches processed(0.3738512444038561%), ce loss 1.5817253589630127\n",
      "202000 batches processed(0.37571120084367626%), ce loss 1.421087384223938\n",
      "203000 batches processed(0.37757115728349644%), ce loss 1.3286709785461426\n",
      "204000 batches processed(0.3794311137233166%), ce loss 1.251652717590332\n",
      "205000 batches processed(0.3812910701631368%), ce loss 1.3794916868209839\n",
      "206000 batches processed(0.38315102660295697%), ce loss 1.4249917268753052\n",
      "207000 batches processed(0.38501098304277714%), ce loss 1.5412358045578003\n",
      "208000 batches processed(0.3868709394825973%), ce loss 1.55808687210083\n",
      "209000 batches processed(0.3887308959224175%), ce loss 1.5789806842803955\n",
      "210000 batches processed(0.3905908523622377%), ce loss 1.465489149093628\n",
      "211000 batches processed(0.39245080880205785%), ce loss 1.6574630737304688\n",
      "212000 batches processed(0.394310765241878%), ce loss 1.5901291370391846\n",
      "213000 batches processed(0.3961707216816982%), ce loss 1.2938427925109863\n",
      "214000 batches processed(0.3980306781215184%), ce loss 1.2652709484100342\n",
      "215000 batches processed(0.39989063456133855%), ce loss 1.5537753105163574\n",
      "216000 batches processed(0.40175059100115873%), ce loss 1.6633491516113281\n",
      "217000 batches processed(0.4036105474409789%), ce loss 1.5559922456741333\n",
      "218000 batches processed(0.40547050388079914%), ce loss 1.2752141952514648\n",
      "219000 batches processed(0.4073304603206193%), ce loss 1.507686734199524\n",
      "220000 batches processed(0.4091904167604395%), ce loss 1.3346644639968872\n",
      "221000 batches processed(0.41105037320025967%), ce loss 1.4357876777648926\n",
      "222000 batches processed(0.41291032964007984%), ce loss 1.7595388889312744\n",
      "223000 batches processed(0.4147702860799%), ce loss 1.558290958404541\n",
      "224000 batches processed(0.4166302425197202%), ce loss 1.5566657781600952\n",
      "225000 batches processed(0.41849019895954037%), ce loss 1.4551326036453247\n",
      "226000 batches processed(0.42035015539936055%), ce loss 1.4686198234558105\n",
      "227000 batches processed(0.4222101118391807%), ce loss 1.3043944835662842\n",
      "228000 batches processed(0.4240700682790009%), ce loss 1.427772045135498\n",
      "229000 batches processed(0.4259300247188211%), ce loss 1.4944615364074707\n",
      "230000 batches processed(0.42778998115864125%), ce loss 1.5029630661010742\n",
      "231000 batches processed(0.42964993759846143%), ce loss 1.2959457635879517\n",
      "232000 batches processed(0.4315098940382816%), ce loss 1.4100406169891357\n",
      "233000 batches processed(0.4333698504781018%), ce loss 1.7962566614151\n",
      "234000 batches processed(0.43522980691792196%), ce loss 1.4217795133590698\n",
      "235000 batches processed(0.4370897633577422%), ce loss 1.55503249168396\n",
      "236000 batches processed(0.43894971979756237%), ce loss 1.4914096593856812\n",
      "237000 batches processed(0.44080967623738254%), ce loss 1.307643175125122\n",
      "238000 batches processed(0.4426696326772027%), ce loss 1.5268409252166748\n",
      "239000 batches processed(0.4445295891170229%), ce loss 1.2504727840423584\n",
      "240000 batches processed(0.44638954555684307%), ce loss 1.365382432937622\n",
      "241000 batches processed(0.44824950199666325%), ce loss 1.4684451818466187\n",
      "242000 batches processed(0.4501094584364834%), ce loss 1.32120943069458\n",
      "243000 batches processed(0.4519694148763036%), ce loss 1.4937307834625244\n",
      "244000 batches processed(0.4538293713161238%), ce loss 1.5167073011398315\n",
      "245000 batches processed(0.45568932775594395%), ce loss 1.3490506410598755\n",
      "246000 batches processed(0.4575492841957641%), ce loss 1.6005988121032715\n",
      "247000 batches processed(0.4594092406355843%), ce loss 1.587497591972351\n",
      "248000 batches processed(0.4612691970754045%), ce loss 1.2732292413711548\n",
      "249000 batches processed(0.46312915351522466%), ce loss 1.5261646509170532\n",
      "250000 batches processed(0.46498910995504483%), ce loss 1.4370967149734497\n",
      "251000 batches processed(0.466849066394865%), ce loss 1.2479274272918701\n",
      "252000 batches processed(0.4687090228346852%), ce loss 1.539046287536621\n",
      "253000 batches processed(0.4705689792745054%), ce loss 1.3264106512069702\n",
      "254000 batches processed(0.4724289357143256%), ce loss 1.5109704732894897\n",
      "255000 batches processed(0.47428889215414577%), ce loss 1.3734513521194458\n",
      "256000 batches processed(0.47614884859396595%), ce loss 1.6145020723342896\n",
      "257000 batches processed(0.4780088050337861%), ce loss 1.3948341608047485\n",
      "258000 batches processed(0.4798687614736063%), ce loss 1.3098540306091309\n",
      "259000 batches processed(0.4817287179134265%), ce loss 1.3905959129333496\n",
      "260000 batches processed(0.48358867435324665%), ce loss 1.5458804368972778\n",
      "261000 batches processed(0.4854486307930668%), ce loss 1.5168349742889404\n",
      "262000 batches processed(0.487308587232887%), ce loss 1.308740258216858\n",
      "263000 batches processed(0.4891685436727072%), ce loss 1.5194084644317627\n",
      "264000 batches processed(0.49102850011252736%), ce loss 1.4708011150360107\n",
      "265000 batches processed(0.49288845655234753%), ce loss 1.669314980506897\n",
      "266000 batches processed(0.4947484129921677%), ce loss 1.3647589683532715\n",
      "267000 batches processed(0.4966083694319879%), ce loss 1.3797224760055542\n",
      "268000 batches processed(0.49846832587180806%), ce loss 1.552483081817627\n",
      "269000 batches processed(0.5003282823116283%), ce loss 1.5931628942489624\n",
      "270000 batches processed(0.5021882387514485%), ce loss 1.7104929685592651\n",
      "271000 batches processed(0.5040481951912686%), ce loss 1.3086010217666626\n",
      "272000 batches processed(0.5059081516310888%), ce loss 1.3689419031143188\n",
      "273000 batches processed(0.507768108070909%), ce loss 1.4187982082366943\n",
      "274000 batches processed(0.5096280645107292%), ce loss 1.6201938390731812\n",
      "275000 batches processed(0.5114880209505493%), ce loss 1.308924913406372\n",
      "276000 batches processed(0.5133479773903695%), ce loss 1.5049630403518677\n",
      "277000 batches processed(0.5152079338301897%), ce loss 1.4853421449661255\n",
      "278000 batches processed(0.5170678902700099%), ce loss 1.5875799655914307\n",
      "279000 batches processed(0.51892784670983%), ce loss 1.5260186195373535\n",
      "280000 batches processed(0.5207878031496502%), ce loss 1.4624269008636475\n",
      "281000 batches processed(0.5226477595894704%), ce loss 1.53422212600708\n",
      "282000 batches processed(0.5245077160292906%), ce loss 1.4623489379882812\n",
      "283000 batches processed(0.5263676724691108%), ce loss 1.4626485109329224\n",
      "284000 batches processed(0.5282276289089309%), ce loss 1.468827486038208\n",
      "285000 batches processed(0.5300875853487511%), ce loss 1.5975369215011597\n",
      "286000 batches processed(0.5319475417885713%), ce loss 1.4170210361480713\n",
      "287000 batches processed(0.5338074982283915%), ce loss 1.524064064025879\n",
      "288000 batches processed(0.5356674546682116%), ce loss 1.3754490613937378\n",
      "289000 batches processed(0.5375274111080318%), ce loss 1.429091453552246\n",
      "290000 batches processed(0.539387367547852%), ce loss 1.2929539680480957\n",
      "291000 batches processed(0.5412473239876722%), ce loss 1.6305880546569824\n",
      "292000 batches processed(0.5431072804274923%), ce loss 1.6039947271347046\n",
      "293000 batches processed(0.5449672368673125%), ce loss 1.4157557487487793\n",
      "294000 batches processed(0.5468271933071327%), ce loss 1.4181468486785889\n",
      "295000 batches processed(0.5486871497469529%), ce loss 1.541896104812622\n",
      "296000 batches processed(0.5505471061867732%), ce loss 1.5247496366500854\n",
      "297000 batches processed(0.5524070626265933%), ce loss 1.6132007837295532\n",
      "298000 batches processed(0.5542670190664135%), ce loss 1.6206060647964478\n",
      "299000 batches processed(0.5561269755062337%), ce loss 1.2311891317367554\n",
      "300000 batches processed(0.5579869319460539%), ce loss 1.5485601425170898\n",
      "301000 batches processed(0.559846888385874%), ce loss 1.500067949295044\n",
      "302000 batches processed(0.5617068448256942%), ce loss 1.2922616004943848\n",
      "303000 batches processed(0.5635668012655144%), ce loss 1.6091760396957397\n",
      "304000 batches processed(0.5654267577053346%), ce loss 1.4691020250320435\n",
      "305000 batches processed(0.5672867141451547%), ce loss 1.1737676858901978\n",
      "306000 batches processed(0.5691466705849749%), ce loss 1.5239721536636353\n",
      "307000 batches processed(0.5710066270247951%), ce loss 1.4165048599243164\n",
      "308000 batches processed(0.5728665834646153%), ce loss 1.3032969236373901\n",
      "309000 batches processed(0.5747265399044355%), ce loss 1.4427434206008911\n",
      "310000 batches processed(0.5765864963442556%), ce loss 1.3567789793014526\n",
      "311000 batches processed(0.5784464527840758%), ce loss 1.4603877067565918\n",
      "312000 batches processed(0.580306409223896%), ce loss 1.3965506553649902\n",
      "313000 batches processed(0.5821663656637162%), ce loss 1.4407286643981934\n",
      "314000 batches processed(0.5840263221035363%), ce loss 1.203950047492981\n",
      "315000 batches processed(0.5858862785433565%), ce loss 1.399938702583313\n",
      "316000 batches processed(0.5877462349831767%), ce loss 1.5679959058761597\n",
      "317000 batches processed(0.5896061914229969%), ce loss 1.4977465867996216\n",
      "318000 batches processed(0.591466147862817%), ce loss 1.1358399391174316\n",
      "319000 batches processed(0.5933261043026372%), ce loss 1.485826015472412\n",
      "320000 batches processed(0.5951860607424574%), ce loss 1.4792248010635376\n",
      "321000 batches processed(0.5970460171822776%), ce loss 1.7135783433914185\n",
      "322000 batches processed(0.5989059736220977%), ce loss 1.3736642599105835\n",
      "323000 batches processed(0.6007659300619179%), ce loss 1.5081382989883423\n",
      "324000 batches processed(0.6026258865017381%), ce loss 1.324581265449524\n",
      "325000 batches processed(0.6044858429415583%), ce loss 1.5721365213394165\n",
      "326000 batches processed(0.6063457993813784%), ce loss 1.3142895698547363\n",
      "327000 batches processed(0.6082057558211986%), ce loss 1.3409582376480103\n",
      "328000 batches processed(0.6100657122610188%), ce loss 1.6713173389434814\n",
      "329000 batches processed(0.611925668700839%), ce loss 1.412412405014038\n",
      "330000 batches processed(0.6137856251406592%), ce loss 1.4656542539596558\n",
      "331000 batches processed(0.6156455815804794%), ce loss 1.5432403087615967\n",
      "332000 batches processed(0.6175055380202996%), ce loss 1.3274712562561035\n",
      "333000 batches processed(0.6193654944601198%), ce loss 1.3314405679702759\n",
      "334000 batches processed(0.62122545089994%), ce loss 1.5759259462356567\n",
      "335000 batches processed(0.6230854073397601%), ce loss 1.5798879861831665\n",
      "336000 batches processed(0.6249453637795803%), ce loss 1.1156519651412964\n",
      "337000 batches processed(0.6268053202194005%), ce loss 1.31657075881958\n",
      "338000 batches processed(0.6286652766592207%), ce loss 1.346693992614746\n",
      "339000 batches processed(0.6305252330990408%), ce loss 1.329511284828186\n",
      "340000 batches processed(0.632385189538861%), ce loss 1.175862431526184\n",
      "341000 batches processed(0.6342451459786812%), ce loss 1.2651898860931396\n",
      "342000 batches processed(0.6361051024185014%), ce loss 1.3192437887191772\n",
      "343000 batches processed(0.6379650588583216%), ce loss 1.6274577379226685\n",
      "344000 batches processed(0.6398250152981417%), ce loss 1.4285815954208374\n",
      "345000 batches processed(0.6416849717379619%), ce loss 1.4719756841659546\n",
      "346000 batches processed(0.6435449281777821%), ce loss 1.3938844203948975\n",
      "347000 batches processed(0.6454048846176023%), ce loss 1.3132060766220093\n",
      "348000 batches processed(0.6472648410574224%), ce loss 1.3814458847045898\n",
      "349000 batches processed(0.6491247974972426%), ce loss 1.6124207973480225\n",
      "350000 batches processed(0.6509847539370628%), ce loss 1.3667200803756714\n",
      "351000 batches processed(0.652844710376883%), ce loss 1.345577359199524\n",
      "352000 batches processed(0.6547046668167031%), ce loss 1.445603609085083\n",
      "353000 batches processed(0.6565646232565233%), ce loss 1.4237045049667358\n",
      "354000 batches processed(0.6584245796963435%), ce loss 1.1117384433746338\n",
      "355000 batches processed(0.6602845361361637%), ce loss 1.6018022298812866\n",
      "356000 batches processed(0.6621444925759838%), ce loss 1.7352639436721802\n",
      "357000 batches processed(0.664004449015804%), ce loss 1.320074439048767\n",
      "358000 batches processed(0.6658644054556242%), ce loss 1.3869273662567139\n",
      "359000 batches processed(0.6677243618954444%), ce loss 1.5289443731307983\n",
      "360000 batches processed(0.6695843183352646%), ce loss 1.4036757946014404\n",
      "361000 batches processed(0.6714442747750847%), ce loss 1.2833553552627563\n",
      "362000 batches processed(0.6733042312149049%), ce loss 1.649387001991272\n",
      "363000 batches processed(0.6751641876547251%), ce loss 1.3444533348083496\n",
      "364000 batches processed(0.6770241440945453%), ce loss 1.4652310609817505\n",
      "365000 batches processed(0.6788841005343654%), ce loss 1.682816743850708\n",
      "366000 batches processed(0.6807440569741857%), ce loss 1.4803334474563599\n",
      "367000 batches processed(0.6826040134140059%), ce loss 1.2442448139190674\n",
      "368000 batches processed(0.6844639698538261%), ce loss 1.4447256326675415\n",
      "369000 batches processed(0.6863239262936462%), ce loss 1.4205865859985352\n",
      "370000 batches processed(0.6881838827334664%), ce loss 1.4660855531692505\n",
      "371000 batches processed(0.6900438391732866%), ce loss 1.3545602560043335\n",
      "372000 batches processed(0.6919037956131068%), ce loss 1.5555810928344727\n",
      "373000 batches processed(0.693763752052927%), ce loss 1.41069757938385\n",
      "374000 batches processed(0.6956237084927471%), ce loss 1.578517198562622\n",
      "375000 batches processed(0.6974836649325673%), ce loss 1.4795565605163574\n",
      "376000 batches processed(0.6993436213723875%), ce loss 1.5974202156066895\n",
      "377000 batches processed(0.7012035778122077%), ce loss 1.2399524450302124\n",
      "378000 batches processed(0.7030635342520278%), ce loss 1.3683925867080688\n",
      "379000 batches processed(0.704923490691848%), ce loss 1.3603702783584595\n",
      "380000 batches processed(0.7067834471316682%), ce loss 1.4712082147598267\n",
      "381000 batches processed(0.7086434035714884%), ce loss 1.4340484142303467\n",
      "382000 batches processed(0.7105033600113085%), ce loss 1.4299850463867188\n",
      "383000 batches processed(0.7123633164511287%), ce loss 1.3224225044250488\n",
      "384000 batches processed(0.7142232728909489%), ce loss 1.3914059400558472\n",
      "385000 batches processed(0.7160832293307691%), ce loss 1.2910672426223755\n",
      "386000 batches processed(0.7179431857705892%), ce loss 1.498518705368042\n",
      "387000 batches processed(0.7198031422104094%), ce loss 1.4781544208526611\n",
      "388000 batches processed(0.7216630986502296%), ce loss 1.4868993759155273\n",
      "389000 batches processed(0.7235230550900498%), ce loss 1.552052617073059\n",
      "390000 batches processed(0.72538301152987%), ce loss 1.3109538555145264\n",
      "391000 batches processed(0.7272429679696901%), ce loss 1.53383207321167\n",
      "392000 batches processed(0.7291029244095103%), ce loss 1.576370120048523\n",
      "393000 batches processed(0.7309628808493305%), ce loss 1.356438159942627\n",
      "394000 batches processed(0.7328228372891507%), ce loss 1.4404730796813965\n",
      "395000 batches processed(0.7346827937289708%), ce loss 1.4251703023910522\n",
      "396000 batches processed(0.736542750168791%), ce loss 1.4536147117614746\n",
      "397000 batches processed(0.7384027066086112%), ce loss 1.4468096494674683\n",
      "398000 batches processed(0.7402626630484314%), ce loss 1.4594416618347168\n",
      "399000 batches processed(0.7421226194882515%), ce loss 1.307121753692627\n",
      "400000 batches processed(0.7439825759280717%), ce loss 1.3148703575134277\n",
      "401000 batches processed(0.745842532367892%), ce loss 1.1425998210906982\n",
      "402000 batches processed(0.7477024888077122%), ce loss 1.5628137588500977\n",
      "403000 batches processed(0.7495624452475323%), ce loss 1.6242005825042725\n",
      "404000 batches processed(0.7514224016873525%), ce loss 1.3136416673660278\n",
      "405000 batches processed(0.7532823581271727%), ce loss 1.4438270330429077\n",
      "406000 batches processed(0.7551423145669929%), ce loss 1.418262004852295\n",
      "407000 batches processed(0.757002271006813%), ce loss 1.4624457359313965\n",
      "408000 batches processed(0.7588622274466332%), ce loss 1.4838309288024902\n",
      "409000 batches processed(0.7607221838864534%), ce loss 1.5152199268341064\n",
      "410000 batches processed(0.7625821403262736%), ce loss 1.2919293642044067\n",
      "411000 batches processed(0.7644420967660938%), ce loss 1.4711819887161255\n",
      "412000 batches processed(0.7663020532059139%), ce loss 1.366551160812378\n",
      "413000 batches processed(0.7681620096457341%), ce loss 1.4586659669876099\n",
      "414000 batches processed(0.7700219660855543%), ce loss 1.4324473142623901\n",
      "415000 batches processed(0.7718819225253745%), ce loss 1.3446784019470215\n",
      "416000 batches processed(0.7737418789651946%), ce loss 1.2723488807678223\n",
      "417000 batches processed(0.7756018354050148%), ce loss 1.3915492296218872\n",
      "418000 batches processed(0.777461791844835%), ce loss 1.6228973865509033\n",
      "419000 batches processed(0.7793217482846552%), ce loss 1.221571445465088\n",
      "420000 batches processed(0.7811817047244753%), ce loss 1.473567008972168\n",
      "421000 batches processed(0.7830416611642955%), ce loss 1.3521190881729126\n",
      "422000 batches processed(0.7849016176041157%), ce loss 1.4462215900421143\n",
      "423000 batches processed(0.7867615740439359%), ce loss 1.214093565940857\n",
      "424000 batches processed(0.788621530483756%), ce loss 1.4774821996688843\n",
      "425000 batches processed(0.7904814869235762%), ce loss 1.5047160387039185\n",
      "426000 batches processed(0.7923414433633964%), ce loss 1.6129772663116455\n",
      "427000 batches processed(0.7942013998032166%), ce loss 1.669836163520813\n",
      "428000 batches processed(0.7960613562430368%), ce loss 1.3584438562393188\n",
      "429000 batches processed(0.7979213126828569%), ce loss 1.6057336330413818\n",
      "430000 batches processed(0.7997812691226771%), ce loss 1.3858026266098022\n",
      "431000 batches processed(0.8016412255624973%), ce loss 1.5160226821899414\n",
      "432000 batches processed(0.8035011820023175%), ce loss 1.3273863792419434\n",
      "433000 batches processed(0.8053611384421376%), ce loss 1.473013162612915\n",
      "434000 batches processed(0.8072210948819578%), ce loss 1.3287956714630127\n",
      "435000 batches processed(0.809081051321778%), ce loss 1.5465447902679443\n",
      "436000 batches processed(0.8109410077615983%), ce loss 1.503902792930603\n",
      "437000 batches processed(0.8128009642014185%), ce loss 1.4677886962890625\n",
      "438000 batches processed(0.8146609206412386%), ce loss 1.3874322175979614\n",
      "439000 batches processed(0.8165208770810588%), ce loss 1.335179090499878\n",
      "440000 batches processed(0.818380833520879%), ce loss 1.38289213180542\n",
      "441000 batches processed(0.8202407899606992%), ce loss 1.4521987438201904\n",
      "442000 batches processed(0.8221007464005193%), ce loss 1.385481834411621\n",
      "443000 batches processed(0.8239607028403395%), ce loss 1.5447062253952026\n",
      "444000 batches processed(0.8258206592801597%), ce loss 1.4493869543075562\n",
      "445000 batches processed(0.8276806157199799%), ce loss 1.6761093139648438\n",
      "446000 batches processed(0.8295405721598%), ce loss 1.396716594696045\n",
      "447000 batches processed(0.8314005285996202%), ce loss 1.519331693649292\n",
      "448000 batches processed(0.8332604850394404%), ce loss 1.4447270631790161\n",
      "449000 batches processed(0.8351204414792606%), ce loss 1.385975956916809\n",
      "450000 batches processed(0.8369803979190807%), ce loss 1.7633289098739624\n",
      "451000 batches processed(0.8388403543589009%), ce loss 1.4921947717666626\n",
      "452000 batches processed(0.8407003107987211%), ce loss 1.5136282444000244\n",
      "453000 batches processed(0.8425602672385413%), ce loss 1.4002975225448608\n",
      "454000 batches processed(0.8444202236783614%), ce loss 1.6009833812713623\n",
      "455000 batches processed(0.8462801801181816%), ce loss 1.2989318370819092\n",
      "456000 batches processed(0.8481401365580018%), ce loss 1.6377229690551758\n",
      "457000 batches processed(0.850000092997822%), ce loss 1.5862057209014893\n",
      "458000 batches processed(0.8518600494376422%), ce loss 1.171459674835205\n",
      "459000 batches processed(0.8537200058774623%), ce loss 1.3776168823242188\n",
      "460000 batches processed(0.8555799623172825%), ce loss 1.5660717487335205\n",
      "461000 batches processed(0.8574399187571027%), ce loss 1.2067131996154785\n",
      "462000 batches processed(0.8592998751969229%), ce loss 1.4440606832504272\n",
      "463000 batches processed(0.861159831636743%), ce loss 1.5105490684509277\n",
      "464000 batches processed(0.8630197880765632%), ce loss 1.6239532232284546\n",
      "465000 batches processed(0.8648797445163834%), ce loss 1.4737430810928345\n",
      "466000 batches processed(0.8667397009562036%), ce loss 1.4827364683151245\n",
      "467000 batches processed(0.8685996573960237%), ce loss 1.4125193357467651\n",
      "468000 batches processed(0.8704596138358439%), ce loss 1.54215669631958\n",
      "469000 batches processed(0.8723195702756641%), ce loss 1.2431281805038452\n",
      "470000 batches processed(0.8741795267154844%), ce loss 1.4823566675186157\n",
      "471000 batches processed(0.8760394831553046%), ce loss 1.6209408044815063\n",
      "472000 batches processed(0.8778994395951247%), ce loss 1.5663162469863892\n",
      "473000 batches processed(0.8797593960349449%), ce loss 1.5923739671707153\n",
      "474000 batches processed(0.8816193524747651%), ce loss 1.1947261095046997\n",
      "475000 batches processed(0.8834793089145853%), ce loss 1.6777957677841187\n",
      "476000 batches processed(0.8853392653544054%), ce loss 1.549837350845337\n",
      "477000 batches processed(0.8871992217942256%), ce loss 1.6946206092834473\n",
      "478000 batches processed(0.8890591782340458%), ce loss 1.309873342514038\n",
      "479000 batches processed(0.890919134673866%), ce loss 1.2979027032852173\n",
      "480000 batches processed(0.8927790911136861%), ce loss 1.4540185928344727\n",
      "481000 batches processed(0.8946390475535063%), ce loss 1.4112483263015747\n",
      "482000 batches processed(0.8964990039933265%), ce loss 1.4023535251617432\n",
      "483000 batches processed(0.8983589604331467%), ce loss 1.5707650184631348\n",
      "484000 batches processed(0.9002189168729668%), ce loss 1.2814258337020874\n",
      "485000 batches processed(0.902078873312787%), ce loss 1.500756025314331\n",
      "486000 batches processed(0.9039388297526072%), ce loss 1.3276809453964233\n",
      "487000 batches processed(0.9057987861924274%), ce loss 1.4276989698410034\n",
      "488000 batches processed(0.9076587426322476%), ce loss 1.5943727493286133\n",
      "489000 batches processed(0.9095186990720677%), ce loss 1.4655200242996216\n",
      "490000 batches processed(0.9113786555118879%), ce loss 1.6852335929870605\n",
      "491000 batches processed(0.9132386119517081%), ce loss 1.6531742811203003\n",
      "492000 batches processed(0.9150985683915283%), ce loss 1.584334135055542\n",
      "493000 batches processed(0.9169585248313484%), ce loss 1.420772910118103\n",
      "494000 batches processed(0.9188184812711686%), ce loss 1.487984299659729\n",
      "495000 batches processed(0.9206784377109888%), ce loss 1.3126404285430908\n",
      "496000 batches processed(0.922538394150809%), ce loss 1.352818250656128\n",
      "497000 batches processed(0.9243983505906291%), ce loss 1.3969802856445312\n",
      "498000 batches processed(0.9262583070304493%), ce loss 1.5203313827514648\n",
      "499000 batches processed(0.9281182634702695%), ce loss 1.2749476432800293\n",
      "500000 batches processed(0.9299782199100897%), ce loss 1.4652291536331177\n",
      "501000 batches processed(0.9318381763499098%), ce loss 1.3796402215957642\n",
      "502000 batches processed(0.93369813278973%), ce loss 1.4589526653289795\n",
      "503000 batches processed(0.9355580892295502%), ce loss 1.4287834167480469\n",
      "504000 batches processed(0.9374180456693704%), ce loss 1.6175869703292847\n",
      "505000 batches processed(0.9392780021091907%), ce loss 1.4924359321594238\n",
      "506000 batches processed(0.9411379585490108%), ce loss 1.5821374654769897\n",
      "507000 batches processed(0.942997914988831%), ce loss 1.6274194717407227\n",
      "508000 batches processed(0.9448578714286512%), ce loss 1.4176489114761353\n",
      "509000 batches processed(0.9467178278684714%), ce loss 1.4365484714508057\n",
      "510000 batches processed(0.9485777843082915%), ce loss 1.3799257278442383\n",
      "511000 batches processed(0.9504377407481117%), ce loss 1.4631085395812988\n",
      "512000 batches processed(0.9522976971879319%), ce loss 1.4569226503372192\n",
      "513000 batches processed(0.9541576536277521%), ce loss 1.4050581455230713\n",
      "514000 batches processed(0.9560176100675722%), ce loss 1.6492395401000977\n",
      "515000 batches processed(0.9578775665073924%), ce loss 1.4172239303588867\n",
      "516000 batches processed(0.9597375229472126%), ce loss 1.3114149570465088\n",
      "517000 batches processed(0.9615974793870328%), ce loss 1.3921583890914917\n",
      "518000 batches processed(0.963457435826853%), ce loss 1.4975396394729614\n",
      "519000 batches processed(0.9653173922666731%), ce loss 1.3190619945526123\n",
      "520000 batches processed(0.9671773487064933%), ce loss 1.348660945892334\n",
      "521000 batches processed(0.9690373051463135%), ce loss 1.527421236038208\n",
      "522000 batches processed(0.9708972615861337%), ce loss 1.3055424690246582\n",
      "523000 batches processed(0.9727572180259538%), ce loss 1.4448145627975464\n",
      "524000 batches processed(0.974617174465774%), ce loss 1.4819235801696777\n",
      "525000 batches processed(0.9764771309055942%), ce loss 1.2555904388427734\n",
      "526000 batches processed(0.9783370873454144%), ce loss 1.4648278951644897\n",
      "527000 batches processed(0.9801970437852345%), ce loss 1.4672141075134277\n",
      "528000 batches processed(0.9820570002250547%), ce loss 1.2401249408721924\n",
      "529000 batches processed(0.9839169566648749%), ce loss 1.3359789848327637\n",
      "530000 batches processed(0.9857769131046951%), ce loss 1.4691271781921387\n",
      "531000 batches processed(0.9876368695445152%), ce loss 1.6475147008895874\n",
      "532000 batches processed(0.9894968259843354%), ce loss 1.470552682876587\n",
      "533000 batches processed(0.9913567824241556%), ce loss 1.5960028171539307\n",
      "534000 batches processed(0.9932167388639758%), ce loss 1.6300734281539917\n",
      "535000 batches processed(0.9950766953037959%), ce loss 1.4971505403518677\n",
      "536000 batches processed(0.9969366517436161%), ce loss 1.389638066291809\n",
      "537000 batches processed(0.9987966081834363%), ce loss 1.48934006690979\n",
      "After epoch 1, ce loss is 1.4388809204101562\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD, Adam\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# optimizer = SGD(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = SGD(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "criterion = nn.NLLLoss().to(device)\n",
    "num_epoch = 1\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=2, collate_fn=collate_self_supervision, shuffle=True)\n",
    "for k in range(1, num_epoch+1):\n",
    "    print(f'--- epoch {k} ---')\n",
    "    try:\n",
    "        for i, data in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            texts, label = data     # label shape: [batch, seq_len]\n",
    "            pred = model(texts.to(device)) # batch, seq_len, n_tokens\n",
    "            loss = criterion(pred.transpose(1, 2), label.to(device))\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(f'{i} batches processed({i/len(data_loader)}%), ce loss {loss}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}, batch idx {i}, epoch idx {k}\")\n",
    "\n",
    "    print(f\"After epoch {k}, ce loss is {loss}\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    After training:\n",
      "    prompt: to be or not to be\n",
      "    next seq:  a sentence to the season to the season to the season to the season to the season to the season to the season to the season to the season to the season to the season to the season to the season to the\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "prompt = 'Barack Obama was born in Honolulu, Hawaii. He was born in'\n",
    "prompt = 'to be or not to be'\n",
    "print(\n",
    "    f\"\"\"\n",
    "    After training:\n",
    "    prompt: {prompt}\n",
    "    next seq: {generate(prompt, model, length=200)}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- sampling and temperature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
