{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text generation example with char-rnn\n",
    "\n",
    "First to load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def download_text(url):\n",
    "    # Send a HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "url = 'https://homl.info/shakespeare'\n",
    "text_data = download_text(url)\n",
    "if text_data:\n",
    "    print(\"Data downloaded successfully!\")\n",
    "else:\n",
    "    print(\"Failed to download data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Vocab and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o': 2, 'm': 3, 'v': 4, 'u': 5, 'h': 6, \"'\": 7, 't': 8, 'w': 9, 'b': 10, 'p': 11, 'c': 12, '&': 13, '-': 14, ' ': 15, '!': 16, 'j': 17, 'r': 18, 'q': 19, '$': 20, ';': 21, ':': 22, 'e': 23, '?': 24, 's': 25, 'n': 26, 'z': 27, 'i': 28, 'l': 29, 'g': 30, ',': 31, 'y': 32, '3': 33, 'x': 34, 'a': 35, 'd': 36, 'k': 37, '.': 38, 'f': 39, '<UNK>': 1, '<PAD>': 0}\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for char in text_data:\n",
    "    if char != '\\n':\n",
    "        vocab.add(char.lower())\n",
    "\n",
    "vocab_mapping = {char:i+2 for i, char in enumerate(vocab)} # 0 for padding and 1 for unknown\n",
    "vocab_mapping['<UNK>'] = 1\n",
    "vocab_mapping['<PAD>'] = 0\n",
    "print(vocab_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of example data: [torch.Size([2, 100]), torch.Size([2, 100])]\n",
      "(tensor([[39, 28, 18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22, 10, 23, 39,  2,\n",
      "         18, 23, 15,  9, 23, 15, 11, 18,  2, 12, 23, 23, 36, 15, 35, 26, 32, 15,\n",
      "         39,  5, 18,  8,  6, 23, 18, 31, 15,  6, 23, 35, 18, 15,  3, 23, 15, 25,\n",
      "         11, 23, 35, 37, 38, 35, 29, 29, 22, 25, 11, 23, 35, 37, 31, 15, 25, 11,\n",
      "         23, 35, 37, 38, 39, 28, 18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22,\n",
      "         32,  2,  5, 15, 35, 18, 23, 15, 35, 29],\n",
      "        [28, 18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22, 10, 23, 39,  2, 18,\n",
      "         23, 15,  9, 23, 15, 11, 18,  2, 12, 23, 23, 36, 15, 35, 26, 32, 15, 39,\n",
      "          5, 18,  8,  6, 23, 18, 31, 15,  6, 23, 35, 18, 15,  3, 23, 15, 25, 11,\n",
      "         23, 35, 37, 38, 35, 29, 29, 22, 25, 11, 23, 35, 37, 31, 15, 25, 11, 23,\n",
      "         35, 37, 38, 39, 28, 18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22, 32,\n",
      "          2,  5, 15, 35, 18, 23, 15, 35, 29, 29]]), tensor([[28, 18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22, 10, 23, 39,  2, 18,\n",
      "         23, 15,  9, 23, 15, 11, 18,  2, 12, 23, 23, 36, 15, 35, 26, 32, 15, 39,\n",
      "          5, 18,  8,  6, 23, 18, 31, 15,  6, 23, 35, 18, 15,  3, 23, 15, 25, 11,\n",
      "         23, 35, 37, 38, 35, 29, 29, 22, 25, 11, 23, 35, 37, 31, 15, 25, 11, 23,\n",
      "         35, 37, 38, 39, 28, 18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22, 32,\n",
      "          2,  5, 15, 35, 18, 23, 15, 35, 29, 29],\n",
      "        [18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22, 10, 23, 39,  2, 18, 23,\n",
      "         15,  9, 23, 15, 11, 18,  2, 12, 23, 23, 36, 15, 35, 26, 32, 15, 39,  5,\n",
      "         18,  8,  6, 23, 18, 31, 15,  6, 23, 35, 18, 15,  3, 23, 15, 25, 11, 23,\n",
      "         35, 37, 38, 35, 29, 29, 22, 25, 11, 23, 35, 37, 31, 15, 25, 11, 23, 35,\n",
      "         37, 38, 39, 28, 18, 25,  8, 15, 12, 28,  8, 28, 27, 23, 26, 22, 32,  2,\n",
      "          5, 15, 35, 18, 23, 15, 35, 29, 29, 15]]))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class TextTransform:\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocab = vocabulary\n",
    "        self.n_tokens = len(vocabulary)\n",
    "        reverse_map = [None] * len(vocabulary)\n",
    "        for k, v in vocabulary.items():\n",
    "            reverse_map[v] = k\n",
    "        self.reverse_map = reverse_map\n",
    "\n",
    "    def __call__(self, text):\n",
    "        # Numericalize tokens\n",
    "        return [self.vocab.get(char.lower(), 1) for char in text]\n",
    "\n",
    "    \n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data: str, transform=None, window_len = 100) -> None:\n",
    "        self.data = data.replace('\\n', '').lower()\n",
    "        self.transform = transform\n",
    "        self.window_len = window_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.window_len -1 # need next few tokens as label\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx:idx+self.window_len]\n",
    "        label = self.data[idx+1:idx+self.window_len+1]\n",
    "        if self.transform:\n",
    "            return self.transform(text), self.transform(label)\n",
    "        else:\n",
    "            return text, label\n",
    "\n",
    "\n",
    "window_len = 100      \n",
    "def collate_self_supervision(batch):\n",
    "    texts, labels = zip(*batch)  # Unzip the tuples into separate lists\n",
    "    texts_tensor = torch.tensor(texts, dtype=torch.long)  # Ensure dtype is long for indices\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)  # Same for labels\n",
    "    return texts_tensor, labels_tensor\n",
    "\n",
    "\n",
    "\n",
    "transform = TextTransform(vocab_mapping)\n",
    "dataset = MyDataset(text_data, transform, window_len)\n",
    "data_loader = DataLoader(dataset, batch_size=2, collate_fn=collate_self_supervision)\n",
    "\n",
    "example_data = data_loader._get_iterator()._next_data()\n",
    "print(f'shapes of example data: {[t.shape for t in example_data]}')\n",
    "print(example_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define your device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, n_tokens, emb_dim=16, GRU_dim=128):\n",
    "        super(CharRNN, self).__init__() \n",
    "        self.embedding = nn.Embedding(n_tokens, emb_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(emb_dim, GRU_dim, batch_first=True)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(GRU_dim, 2*n_tokens),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*n_tokens, n_tokens),\n",
    "        )\n",
    "        self.GRU_dim = GRU_dim\n",
    "    \n",
    "    def forward(self, input):\n",
    "        emb = self.embedding(input)  # [batch, window_len, emb_dim]\n",
    "        seq, _h_n = self.gru(emb)    # [batch, window_len, GRU_dim]\n",
    "        return self.output(seq)       # [batch, window_len, n_tokens]\n",
    "    \n",
    "    def generate(self, input_tensor, length=5, temperature=0.8):\n",
    "        N = len(input_tensor)\n",
    "        h = torch.zeros(size=(1, N, self.GRU_dim)).to(device)\n",
    "\n",
    "        output = []\n",
    "\n",
    "        for _ in range(length):\n",
    "            if len(output) == 0:\n",
    "                input = input_tensor\n",
    "            else:\n",
    "                input = output[-1]\n",
    "            emb = self.embedding(input)  # [batch, window_len, emb_dim]\n",
    "            seq, h = self.gru(emb, h)    # [batch, window_len, GRU_dim]\n",
    "            logits_last = self.output(seq)[:,-1,:]      # [batch, 1, n_tokens]\n",
    "            prob = torch.softmax(logits_last.squeeze(1),dim=1) # [batch, n_tokens]\n",
    "            next_token = torch.multinomial(prob, num_samples=1) #[batch, 1]\n",
    "            output.append(next_token) # [batch, 1]\n",
    "\n",
    "        return output #[batch, length]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate(prompt: str, model, length=5, temperature=0.8) -> str:\n",
    "    input_tensor = torch.tensor(transform(prompt)).unsqueeze(0).to(device)\n",
    "    output_tokens = model.generate(input_tensor, length, temperature)  # Ensure this is on the right device\n",
    "    # print(output_tokens)\n",
    "    return ''.join([transform.reverse_map[idx] for idx in output_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Before training:\n",
      "    prompt: To be or not to be\n",
      "    next seq: 3<UNK>:fi\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Move model to device\n",
    "model = CharRNN(transform.n_tokens).to(device)\n",
    "prompt = 'To be or not to be'\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Before training:\n",
    "    prompt: {prompt}\n",
    "    next seq: {generate(prompt, model, temperature=0.3)}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch 1 ---\n",
      "0 batches processed(0.0%), ce loss 3.6818578243255615\n",
      "1000 batches processed(0.0018599564398201795%), ce loss 2.153061866760254\n",
      "2000 batches processed(0.003719912879640359%), ce loss 1.887107491493225\n",
      "3000 batches processed(0.005579869319460538%), ce loss 1.7397170066833496\n",
      "4000 batches processed(0.007439825759280718%), ce loss 1.6302664279937744\n",
      "5000 batches processed(0.009299782199100897%), ce loss 1.9526563882827759\n",
      "6000 batches processed(0.011159738638921076%), ce loss 1.6232407093048096\n",
      "7000 batches processed(0.013019695078741256%), ce loss 1.7668894529342651\n",
      "8000 batches processed(0.014879651518561436%), ce loss 1.5100713968276978\n",
      "9000 batches processed(0.016739607958381614%), ce loss 1.641817331314087\n",
      "10000 batches processed(0.018599564398201793%), ce loss 1.5486767292022705\n",
      "11000 batches processed(0.020459520838021973%), ce loss 1.3205605745315552\n",
      "12000 batches processed(0.022319477277842153%), ce loss 1.5450106859207153\n",
      "13000 batches processed(0.024179433717662333%), ce loss 1.5944814682006836\n",
      "14000 batches processed(0.026039390157482512%), ce loss 1.471238613128662\n",
      "15000 batches processed(0.027899346597302692%), ce loss 1.6948232650756836\n",
      "16000 batches processed(0.02975930303712287%), ce loss 1.5012856721878052\n",
      "17000 batches processed(0.03161925947694305%), ce loss 1.7673780918121338\n",
      "18000 batches processed(0.03347921591676323%), ce loss 1.7668204307556152\n",
      "19000 batches processed(0.03533917235658341%), ce loss 1.5050281286239624\n",
      "20000 batches processed(0.03719912879640359%), ce loss 1.5184439420700073\n",
      "21000 batches processed(0.03905908523622377%), ce loss 1.5980056524276733\n",
      "22000 batches processed(0.040919041676043946%), ce loss 1.6214675903320312\n",
      "23000 batches processed(0.04277899811586413%), ce loss 1.599774956703186\n",
      "24000 batches processed(0.044638954555684306%), ce loss 1.2987490892410278\n",
      "25000 batches processed(0.04649891099550448%), ce loss 1.390295147895813\n",
      "26000 batches processed(0.048358867435324665%), ce loss 1.5283989906311035\n",
      "27000 batches processed(0.05021882387514484%), ce loss 1.7558164596557617\n",
      "28000 batches processed(0.052078780314965024%), ce loss 1.927536964416504\n",
      "29000 batches processed(0.0539387367547852%), ce loss 1.609824538230896\n",
      "30000 batches processed(0.055798693194605384%), ce loss 1.6599633693695068\n",
      "31000 batches processed(0.05765864963442556%), ce loss 1.362388014793396\n",
      "32000 batches processed(0.05951860607424574%), ce loss 1.460121750831604\n",
      "33000 batches processed(0.06137856251406592%), ce loss 1.507369041442871\n",
      "34000 batches processed(0.0632385189538861%), ce loss 1.718062400817871\n",
      "35000 batches processed(0.06509847539370628%), ce loss 1.4419747591018677\n",
      "36000 batches processed(0.06695843183352646%), ce loss 1.304529070854187\n",
      "37000 batches processed(0.06881838827334665%), ce loss 1.482551097869873\n",
      "38000 batches processed(0.07067834471316682%), ce loss 1.7706091403961182\n",
      "39000 batches processed(0.072538301152987%), ce loss 1.4870193004608154\n",
      "40000 batches processed(0.07439825759280717%), ce loss 1.2599443197250366\n",
      "41000 batches processed(0.07625821403262735%), ce loss 1.3606970310211182\n",
      "42000 batches processed(0.07811817047244754%), ce loss 1.4867724180221558\n",
      "43000 batches processed(0.07997812691226772%), ce loss 1.515379786491394\n",
      "44000 batches processed(0.08183808335208789%), ce loss 1.781463623046875\n",
      "45000 batches processed(0.08369803979190807%), ce loss 1.600386619567871\n",
      "46000 batches processed(0.08555799623172826%), ce loss 1.6530563831329346\n",
      "47000 batches processed(0.08741795267154844%), ce loss 1.8095269203186035\n",
      "48000 batches processed(0.08927790911136861%), ce loss 1.4610308408737183\n",
      "49000 batches processed(0.09113786555118879%), ce loss 1.5211471319198608\n",
      "50000 batches processed(0.09299782199100896%), ce loss 1.4526262283325195\n",
      "51000 batches processed(0.09485777843082915%), ce loss 1.6860709190368652\n",
      "52000 batches processed(0.09671773487064933%), ce loss 1.3180197477340698\n",
      "53000 batches processed(0.0985776913104695%), ce loss 1.6188772916793823\n",
      "54000 batches processed(0.10043764775028968%), ce loss 1.3644723892211914\n",
      "55000 batches processed(0.10229760419010987%), ce loss 1.5267434120178223\n",
      "56000 batches processed(0.10415756062993005%), ce loss 1.4121105670928955\n",
      "57000 batches processed(0.10601751706975023%), ce loss 1.2732232809066772\n",
      "58000 batches processed(0.1078774735095704%), ce loss 1.2586770057678223\n",
      "59000 batches processed(0.10973742994939059%), ce loss 1.5211279392242432\n",
      "60000 batches processed(0.11159738638921077%), ce loss 1.5775567293167114\n",
      "61000 batches processed(0.11345734282903094%), ce loss 1.3236634731292725\n",
      "62000 batches processed(0.11531729926885112%), ce loss 1.2868496179580688\n",
      "63000 batches processed(0.1171772557086713%), ce loss 1.5289297103881836\n",
      "64000 batches processed(0.11903721214849149%), ce loss 1.426650047302246\n",
      "65000 batches processed(0.12089716858831166%), ce loss 1.2182228565216064\n",
      "66000 batches processed(0.12275712502813184%), ce loss 1.3789178133010864\n",
      "67000 batches processed(0.12461708146795202%), ce loss 1.6103650331497192\n",
      "68000 batches processed(0.1264770379077722%), ce loss 1.6166489124298096\n",
      "69000 batches processed(0.12833699434759238%), ce loss 1.6120394468307495\n",
      "70000 batches processed(0.13019695078741256%), ce loss 1.3325872421264648\n",
      "71000 batches processed(0.13205690722723273%), ce loss 1.3553920984268188\n",
      "72000 batches processed(0.1339168636670529%), ce loss 1.3588776588439941\n",
      "73000 batches processed(0.1357768201068731%), ce loss 1.4300445318222046\n",
      "74000 batches processed(0.1376367765466933%), ce loss 1.4985809326171875\n",
      "75000 batches processed(0.13949673298651347%), ce loss 1.355271339416504\n",
      "76000 batches processed(0.14135668942633364%), ce loss 1.3787448406219482\n",
      "77000 batches processed(0.14321664586615382%), ce loss 1.4489446878433228\n",
      "78000 batches processed(0.145076602305974%), ce loss 1.4973840713500977\n",
      "79000 batches processed(0.14693655874579417%), ce loss 1.1828277111053467\n",
      "80000 batches processed(0.14879651518561435%), ce loss 1.5105355978012085\n",
      "81000 batches processed(0.15065647162543452%), ce loss 1.4418350458145142\n",
      "82000 batches processed(0.1525164280652547%), ce loss 1.3531079292297363\n",
      "83000 batches processed(0.1543763845050749%), ce loss 1.3614819049835205\n",
      "84000 batches processed(0.15623634094489508%), ce loss 1.4329255819320679\n",
      "85000 batches processed(0.15809629738471526%), ce loss 1.4614732265472412\n",
      "86000 batches processed(0.15995625382453543%), ce loss 1.6215813159942627\n",
      "87000 batches processed(0.1618162102643556%), ce loss 1.4015414714813232\n",
      "88000 batches processed(0.16367616670417579%), ce loss 1.6293774843215942\n",
      "89000 batches processed(0.16553612314399596%), ce loss 1.4883211851119995\n",
      "90000 batches processed(0.16739607958381614%), ce loss 1.512243390083313\n",
      "91000 batches processed(0.1692560360236363%), ce loss 1.588853120803833\n",
      "92000 batches processed(0.17111599246345652%), ce loss 1.1675808429718018\n",
      "93000 batches processed(0.1729759489032767%), ce loss 1.3909673690795898\n",
      "94000 batches processed(0.17483590534309687%), ce loss 1.430667757987976\n",
      "95000 batches processed(0.17669586178291705%), ce loss 1.6090031862258911\n",
      "96000 batches processed(0.17855581822273722%), ce loss 1.5081322193145752\n",
      "97000 batches processed(0.1804157746625574%), ce loss 1.3604927062988281\n",
      "98000 batches processed(0.18227573110237758%), ce loss 1.4701898097991943\n",
      "99000 batches processed(0.18413568754219775%), ce loss 1.4396302700042725\n",
      "100000 batches processed(0.18599564398201793%), ce loss 1.4485843181610107\n",
      "101000 batches processed(0.18785560042183813%), ce loss 1.4729559421539307\n",
      "102000 batches processed(0.1897155568616583%), ce loss 1.3582541942596436\n",
      "103000 batches processed(0.19157551330147848%), ce loss 1.4297947883605957\n",
      "104000 batches processed(0.19343546974129866%), ce loss 1.4467597007751465\n",
      "105000 batches processed(0.19529542618111884%), ce loss 1.3840446472167969\n",
      "106000 batches processed(0.197155382620939%), ce loss 1.3159031867980957\n",
      "107000 batches processed(0.1990153390607592%), ce loss 1.392065167427063\n",
      "108000 batches processed(0.20087529550057937%), ce loss 1.4240106344223022\n",
      "109000 batches processed(0.20273525194039957%), ce loss 1.6404449939727783\n",
      "110000 batches processed(0.20459520838021975%), ce loss 1.373539686203003\n",
      "111000 batches processed(0.20645516482003992%), ce loss 1.8133323192596436\n",
      "112000 batches processed(0.2083151212598601%), ce loss 1.6533801555633545\n",
      "113000 batches processed(0.21017507769968027%), ce loss 1.5813277959823608\n",
      "114000 batches processed(0.21203503413950045%), ce loss 1.2661795616149902\n",
      "115000 batches processed(0.21389499057932063%), ce loss 1.4430270195007324\n",
      "116000 batches processed(0.2157549470191408%), ce loss 1.628273606300354\n",
      "117000 batches processed(0.21761490345896098%), ce loss 1.3313450813293457\n",
      "118000 batches processed(0.21947485989878118%), ce loss 1.5030173063278198\n",
      "119000 batches processed(0.22133481633860136%), ce loss 1.406435251235962\n",
      "120000 batches processed(0.22319477277842154%), ce loss 1.5744390487670898\n",
      "121000 batches processed(0.2250547292182417%), ce loss 1.48246431350708\n",
      "122000 batches processed(0.2269146856580619%), ce loss 1.3462684154510498\n",
      "123000 batches processed(0.22877464209788206%), ce loss 1.4058635234832764\n",
      "124000 batches processed(0.23063459853770224%), ce loss 1.594606637954712\n",
      "125000 batches processed(0.23249455497752242%), ce loss 1.5837572813034058\n",
      "126000 batches processed(0.2343545114173426%), ce loss 1.6689660549163818\n",
      "127000 batches processed(0.2362144678571628%), ce loss 1.4125324487686157\n",
      "128000 batches processed(0.23807442429698297%), ce loss 1.6116549968719482\n",
      "129000 batches processed(0.23993438073680315%), ce loss 1.592124342918396\n",
      "130000 batches processed(0.24179433717662333%), ce loss 1.5833648443222046\n",
      "131000 batches processed(0.2436542936164435%), ce loss 1.5034369230270386\n",
      "132000 batches processed(0.24551425005626368%), ce loss 1.306062936782837\n",
      "133000 batches processed(0.24737420649608385%), ce loss 1.5545440912246704\n",
      "134000 batches processed(0.24923416293590403%), ce loss 1.4334723949432373\n",
      "135000 batches processed(0.25109411937572423%), ce loss 1.5266951322555542\n",
      "136000 batches processed(0.2529540758155444%), ce loss 1.0869711637496948\n",
      "137000 batches processed(0.2548140322553646%), ce loss 1.2669721841812134\n",
      "138000 batches processed(0.25667398869518476%), ce loss 1.4932628870010376\n",
      "139000 batches processed(0.25853394513500494%), ce loss 1.491085171699524\n",
      "140000 batches processed(0.2603939015748251%), ce loss 1.3288973569869995\n",
      "141000 batches processed(0.2622538580146453%), ce loss 1.3085235357284546\n",
      "142000 batches processed(0.26411381445446547%), ce loss 1.3672308921813965\n",
      "143000 batches processed(0.26597377089428564%), ce loss 1.3868107795715332\n",
      "144000 batches processed(0.2678337273341058%), ce loss 1.4273775815963745\n",
      "145000 batches processed(0.269693683773926%), ce loss 1.6384646892547607\n",
      "146000 batches processed(0.2715536402137462%), ce loss 1.364821434020996\n",
      "147000 batches processed(0.27341359665356635%), ce loss 1.230566382408142\n",
      "148000 batches processed(0.2752735530933866%), ce loss 1.2984685897827148\n",
      "149000 batches processed(0.27713350953320676%), ce loss 1.3849862813949585\n",
      "150000 batches processed(0.27899346597302693%), ce loss 1.3838845491409302\n",
      "151000 batches processed(0.2808534224128471%), ce loss 1.396567940711975\n",
      "152000 batches processed(0.2827133788526673%), ce loss 1.570280909538269\n",
      "153000 batches processed(0.28457333529248746%), ce loss 1.330765962600708\n",
      "154000 batches processed(0.28643329173230764%), ce loss 1.6255770921707153\n",
      "155000 batches processed(0.2882932481721278%), ce loss 1.4688796997070312\n",
      "156000 batches processed(0.290153204611948%), ce loss 1.4710662364959717\n",
      "157000 batches processed(0.29201316105176817%), ce loss 1.6239914894104004\n",
      "158000 batches processed(0.29387311749158834%), ce loss 1.5182989835739136\n",
      "159000 batches processed(0.2957330739314085%), ce loss 1.590049386024475\n",
      "160000 batches processed(0.2975930303712287%), ce loss 1.3984332084655762\n",
      "161000 batches processed(0.29945298681104887%), ce loss 1.4293639659881592\n",
      "162000 batches processed(0.30131294325086905%), ce loss 1.4519670009613037\n",
      "163000 batches processed(0.3031728996906892%), ce loss 1.3336288928985596\n",
      "164000 batches processed(0.3050328561305094%), ce loss 1.4744011163711548\n",
      "165000 batches processed(0.3068928125703296%), ce loss 1.28562593460083\n",
      "166000 batches processed(0.3087527690101498%), ce loss 1.6106576919555664\n",
      "167000 batches processed(0.31061272544997%), ce loss 1.4603309631347656\n",
      "168000 batches processed(0.31247268188979016%), ce loss 1.4302685260772705\n",
      "169000 batches processed(0.31433263832961034%), ce loss 1.4189740419387817\n",
      "170000 batches processed(0.3161925947694305%), ce loss 1.5085558891296387\n",
      "171000 batches processed(0.3180525512092507%), ce loss 1.5507988929748535\n",
      "172000 batches processed(0.31991250764907087%), ce loss 1.5049442052841187\n",
      "173000 batches processed(0.32177246408889104%), ce loss 1.5036066770553589\n",
      "174000 batches processed(0.3236324205287112%), ce loss 1.2586365938186646\n",
      "175000 batches processed(0.3254923769685314%), ce loss 1.4911699295043945\n",
      "176000 batches processed(0.32735233340835157%), ce loss 1.479806661605835\n",
      "177000 batches processed(0.32921228984817175%), ce loss 1.5571775436401367\n",
      "178000 batches processed(0.3310722462879919%), ce loss 1.4901694059371948\n",
      "179000 batches processed(0.3329322027278121%), ce loss 1.5708928108215332\n",
      "180000 batches processed(0.3347921591676323%), ce loss 1.4661507606506348\n",
      "181000 batches processed(0.33665211560745245%), ce loss 1.6039189100265503\n",
      "182000 batches processed(0.3385120720472726%), ce loss 1.3841772079467773\n",
      "183000 batches processed(0.34037202848709286%), ce loss 1.4404356479644775\n",
      "184000 batches processed(0.34223198492691304%), ce loss 1.5853277444839478\n",
      "185000 batches processed(0.3440919413667332%), ce loss 1.2594088315963745\n",
      "186000 batches processed(0.3459518978065534%), ce loss 1.4066296815872192\n",
      "187000 batches processed(0.34781185424637356%), ce loss 1.2799164056777954\n",
      "188000 batches processed(0.34967181068619374%), ce loss 1.436948299407959\n",
      "189000 batches processed(0.3515317671260139%), ce loss 1.5508930683135986\n",
      "190000 batches processed(0.3533917235658341%), ce loss 1.3391616344451904\n",
      "191000 batches processed(0.35525168000565427%), ce loss 1.3509140014648438\n",
      "192000 batches processed(0.35711163644547445%), ce loss 1.4142345190048218\n",
      "193000 batches processed(0.3589715928852946%), ce loss 1.3226830959320068\n",
      "194000 batches processed(0.3608315493251148%), ce loss 1.4726961851119995\n",
      "195000 batches processed(0.362691505764935%), ce loss 1.642147183418274\n",
      "196000 batches processed(0.36455146220475515%), ce loss 1.38264799118042\n",
      "197000 batches processed(0.3664114186445753%), ce loss 1.2587385177612305\n",
      "198000 batches processed(0.3682713750843955%), ce loss 1.2762402296066284\n",
      "199000 batches processed(0.3701313315242157%), ce loss 1.2576037645339966\n",
      "200000 batches processed(0.37199128796403585%), ce loss 1.5504199266433716\n",
      "201000 batches processed(0.3738512444038561%), ce loss 1.4693642854690552\n",
      "202000 batches processed(0.37571120084367626%), ce loss 1.3210738897323608\n",
      "203000 batches processed(0.37757115728349644%), ce loss 1.5920956134796143\n",
      "204000 batches processed(0.3794311137233166%), ce loss 1.5605666637420654\n",
      "205000 batches processed(0.3812910701631368%), ce loss 1.3978039026260376\n",
      "206000 batches processed(0.38315102660295697%), ce loss 1.611056923866272\n",
      "207000 batches processed(0.38501098304277714%), ce loss 1.6345254182815552\n",
      "208000 batches processed(0.3868709394825973%), ce loss 1.472519874572754\n",
      "209000 batches processed(0.3887308959224175%), ce loss 1.3928651809692383\n",
      "210000 batches processed(0.3905908523622377%), ce loss 1.386354684829712\n",
      "211000 batches processed(0.39245080880205785%), ce loss 1.4293075799942017\n",
      "212000 batches processed(0.394310765241878%), ce loss 1.331984281539917\n",
      "213000 batches processed(0.3961707216816982%), ce loss 1.3742939233779907\n",
      "214000 batches processed(0.3980306781215184%), ce loss 1.5805611610412598\n",
      "215000 batches processed(0.39989063456133855%), ce loss 1.4751886129379272\n",
      "216000 batches processed(0.40175059100115873%), ce loss 1.4080817699432373\n",
      "217000 batches processed(0.4036105474409789%), ce loss 1.5818755626678467\n",
      "218000 batches processed(0.40547050388079914%), ce loss 1.4618622064590454\n",
      "219000 batches processed(0.4073304603206193%), ce loss 1.2362828254699707\n",
      "220000 batches processed(0.4091904167604395%), ce loss 1.3966636657714844\n",
      "221000 batches processed(0.41105037320025967%), ce loss 1.5514253377914429\n",
      "222000 batches processed(0.41291032964007984%), ce loss 1.460038185119629\n",
      "223000 batches processed(0.4147702860799%), ce loss 1.1572386026382446\n",
      "224000 batches processed(0.4166302425197202%), ce loss 1.4280527830123901\n",
      "225000 batches processed(0.41849019895954037%), ce loss 1.27833890914917\n",
      "226000 batches processed(0.42035015539936055%), ce loss 1.323126196861267\n",
      "227000 batches processed(0.4222101118391807%), ce loss 1.5039951801300049\n",
      "228000 batches processed(0.4240700682790009%), ce loss 1.2632516622543335\n",
      "229000 batches processed(0.4259300247188211%), ce loss 1.4757072925567627\n",
      "230000 batches processed(0.42778998115864125%), ce loss 1.506905198097229\n",
      "231000 batches processed(0.42964993759846143%), ce loss 1.3800039291381836\n",
      "232000 batches processed(0.4315098940382816%), ce loss 1.3767650127410889\n",
      "233000 batches processed(0.4333698504781018%), ce loss 1.4462790489196777\n",
      "234000 batches processed(0.43522980691792196%), ce loss 1.5639904737472534\n",
      "235000 batches processed(0.4370897633577422%), ce loss 1.3569037914276123\n",
      "236000 batches processed(0.43894971979756237%), ce loss 1.2442030906677246\n",
      "237000 batches processed(0.44080967623738254%), ce loss 1.3696506023406982\n",
      "238000 batches processed(0.4426696326772027%), ce loss 1.5325714349746704\n",
      "239000 batches processed(0.4445295891170229%), ce loss 1.2979071140289307\n",
      "240000 batches processed(0.44638954555684307%), ce loss 1.6804108619689941\n",
      "241000 batches processed(0.44824950199666325%), ce loss 1.2935783863067627\n",
      "242000 batches processed(0.4501094584364834%), ce loss 1.2378337383270264\n",
      "243000 batches processed(0.4519694148763036%), ce loss 1.5609185695648193\n",
      "244000 batches processed(0.4538293713161238%), ce loss 1.3731963634490967\n",
      "245000 batches processed(0.45568932775594395%), ce loss 1.410844087600708\n",
      "246000 batches processed(0.4575492841957641%), ce loss 1.2571603059768677\n",
      "247000 batches processed(0.4594092406355843%), ce loss 1.4385673999786377\n",
      "248000 batches processed(0.4612691970754045%), ce loss 1.3970565795898438\n",
      "249000 batches processed(0.46312915351522466%), ce loss 1.0881547927856445\n",
      "250000 batches processed(0.46498910995504483%), ce loss 1.5170106887817383\n",
      "251000 batches processed(0.466849066394865%), ce loss 1.304842472076416\n",
      "252000 batches processed(0.4687090228346852%), ce loss 1.7010302543640137\n",
      "253000 batches processed(0.4705689792745054%), ce loss 1.5247164964675903\n",
      "254000 batches processed(0.4724289357143256%), ce loss 1.4465069770812988\n",
      "255000 batches processed(0.47428889215414577%), ce loss 1.466223120689392\n",
      "256000 batches processed(0.47614884859396595%), ce loss 1.3060225248336792\n",
      "257000 batches processed(0.4780088050337861%), ce loss 1.3400650024414062\n",
      "258000 batches processed(0.4798687614736063%), ce loss 1.4788082838058472\n",
      "259000 batches processed(0.4817287179134265%), ce loss 1.5008145570755005\n",
      "260000 batches processed(0.48358867435324665%), ce loss 1.2720507383346558\n",
      "261000 batches processed(0.4854486307930668%), ce loss 1.362564206123352\n",
      "262000 batches processed(0.487308587232887%), ce loss 1.447355031967163\n",
      "263000 batches processed(0.4891685436727072%), ce loss 1.5455354452133179\n",
      "264000 batches processed(0.49102850011252736%), ce loss 1.3974151611328125\n",
      "265000 batches processed(0.49288845655234753%), ce loss 1.2539286613464355\n",
      "266000 batches processed(0.4947484129921677%), ce loss 1.4985116720199585\n",
      "267000 batches processed(0.4966083694319879%), ce loss 1.3547443151474\n",
      "268000 batches processed(0.49846832587180806%), ce loss 1.4395976066589355\n",
      "269000 batches processed(0.5003282823116283%), ce loss 1.4262802600860596\n",
      "270000 batches processed(0.5021882387514485%), ce loss 1.6817145347595215\n",
      "271000 batches processed(0.5040481951912686%), ce loss 1.605772852897644\n",
      "272000 batches processed(0.5059081516310888%), ce loss 1.4617259502410889\n",
      "273000 batches processed(0.507768108070909%), ce loss 1.5391862392425537\n",
      "274000 batches processed(0.5096280645107292%), ce loss 1.281046748161316\n",
      "275000 batches processed(0.5114880209505493%), ce loss 1.276435375213623\n",
      "276000 batches processed(0.5133479773903695%), ce loss 1.2724928855895996\n",
      "277000 batches processed(0.5152079338301897%), ce loss 1.309147834777832\n",
      "278000 batches processed(0.5170678902700099%), ce loss 1.422615647315979\n",
      "279000 batches processed(0.51892784670983%), ce loss 1.5251699686050415\n",
      "280000 batches processed(0.5207878031496502%), ce loss 1.1721246242523193\n",
      "281000 batches processed(0.5226477595894704%), ce loss 1.5896801948547363\n",
      "282000 batches processed(0.5245077160292906%), ce loss 1.508164644241333\n",
      "283000 batches processed(0.5263676724691108%), ce loss 1.5033122301101685\n",
      "284000 batches processed(0.5282276289089309%), ce loss 1.5817657709121704\n",
      "285000 batches processed(0.5300875853487511%), ce loss 1.4448221921920776\n",
      "286000 batches processed(0.5319475417885713%), ce loss 1.2533069849014282\n",
      "287000 batches processed(0.5338074982283915%), ce loss 1.3132240772247314\n",
      "288000 batches processed(0.5356674546682116%), ce loss 1.484957218170166\n",
      "289000 batches processed(0.5375274111080318%), ce loss 1.3584246635437012\n",
      "290000 batches processed(0.539387367547852%), ce loss 1.481355905532837\n",
      "291000 batches processed(0.5412473239876722%), ce loss 1.4585258960723877\n",
      "292000 batches processed(0.5431072804274923%), ce loss 1.3917417526245117\n",
      "293000 batches processed(0.5449672368673125%), ce loss 1.3151687383651733\n",
      "294000 batches processed(0.5468271933071327%), ce loss 1.2028740644454956\n",
      "295000 batches processed(0.5486871497469529%), ce loss 1.6238409280776978\n",
      "296000 batches processed(0.5505471061867732%), ce loss 1.4194271564483643\n",
      "297000 batches processed(0.5524070626265933%), ce loss 1.3625004291534424\n",
      "298000 batches processed(0.5542670190664135%), ce loss 1.4514153003692627\n",
      "299000 batches processed(0.5561269755062337%), ce loss 1.2187951803207397\n",
      "300000 batches processed(0.5579869319460539%), ce loss 1.3823336362838745\n",
      "301000 batches processed(0.559846888385874%), ce loss 1.2669013738632202\n",
      "302000 batches processed(0.5617068448256942%), ce loss 1.3781579732894897\n",
      "303000 batches processed(0.5635668012655144%), ce loss 1.5227172374725342\n",
      "304000 batches processed(0.5654267577053346%), ce loss 1.4633080959320068\n",
      "305000 batches processed(0.5672867141451547%), ce loss 1.3541308641433716\n",
      "306000 batches processed(0.5691466705849749%), ce loss 1.4663286209106445\n",
      "307000 batches processed(0.5710066270247951%), ce loss 1.4702078104019165\n",
      "308000 batches processed(0.5728665834646153%), ce loss 1.3049453496932983\n",
      "309000 batches processed(0.5747265399044355%), ce loss 1.4028598070144653\n",
      "310000 batches processed(0.5765864963442556%), ce loss 1.5711404085159302\n",
      "311000 batches processed(0.5784464527840758%), ce loss 1.5312849283218384\n",
      "312000 batches processed(0.580306409223896%), ce loss 1.6471935510635376\n",
      "313000 batches processed(0.5821663656637162%), ce loss 1.3728212118148804\n",
      "314000 batches processed(0.5840263221035363%), ce loss 1.3528605699539185\n",
      "315000 batches processed(0.5858862785433565%), ce loss 1.6578762531280518\n",
      "316000 batches processed(0.5877462349831767%), ce loss 1.5728259086608887\n",
      "317000 batches processed(0.5896061914229969%), ce loss 1.5767616033554077\n",
      "318000 batches processed(0.591466147862817%), ce loss 1.6138919591903687\n",
      "319000 batches processed(0.5933261043026372%), ce loss 1.3511395454406738\n",
      "320000 batches processed(0.5951860607424574%), ce loss 1.2944421768188477\n",
      "321000 batches processed(0.5970460171822776%), ce loss 1.3665732145309448\n",
      "322000 batches processed(0.5989059736220977%), ce loss 1.3103011846542358\n",
      "323000 batches processed(0.6007659300619179%), ce loss 1.5497990846633911\n",
      "324000 batches processed(0.6026258865017381%), ce loss 1.5690317153930664\n",
      "325000 batches processed(0.6044858429415583%), ce loss 1.3910191059112549\n",
      "326000 batches processed(0.6063457993813784%), ce loss 1.48264741897583\n",
      "327000 batches processed(0.6082057558211986%), ce loss 1.4593967199325562\n",
      "328000 batches processed(0.6100657122610188%), ce loss 1.506927490234375\n",
      "329000 batches processed(0.611925668700839%), ce loss 1.2728092670440674\n",
      "330000 batches processed(0.6137856251406592%), ce loss 1.2094346284866333\n",
      "331000 batches processed(0.6156455815804794%), ce loss 1.4191464185714722\n",
      "332000 batches processed(0.6175055380202996%), ce loss 1.3797500133514404\n",
      "333000 batches processed(0.6193654944601198%), ce loss 1.5536913871765137\n",
      "334000 batches processed(0.62122545089994%), ce loss 1.5051968097686768\n",
      "335000 batches processed(0.6230854073397601%), ce loss 1.3296183347702026\n",
      "336000 batches processed(0.6249453637795803%), ce loss 1.3694037199020386\n",
      "337000 batches processed(0.6268053202194005%), ce loss 1.2931721210479736\n",
      "338000 batches processed(0.6286652766592207%), ce loss 1.3125901222229004\n",
      "339000 batches processed(0.6305252330990408%), ce loss 1.4168528318405151\n",
      "340000 batches processed(0.632385189538861%), ce loss 1.4892401695251465\n",
      "341000 batches processed(0.6342451459786812%), ce loss 1.5170553922653198\n",
      "342000 batches processed(0.6361051024185014%), ce loss 1.4845341444015503\n",
      "343000 batches processed(0.6379650588583216%), ce loss 1.6436158418655396\n",
      "344000 batches processed(0.6398250152981417%), ce loss 1.2891738414764404\n",
      "345000 batches processed(0.6416849717379619%), ce loss 1.2035679817199707\n",
      "346000 batches processed(0.6435449281777821%), ce loss 1.4278193712234497\n",
      "347000 batches processed(0.6454048846176023%), ce loss 1.5974667072296143\n",
      "348000 batches processed(0.6472648410574224%), ce loss 1.4107218980789185\n",
      "349000 batches processed(0.6491247974972426%), ce loss 1.3256289958953857\n",
      "350000 batches processed(0.6509847539370628%), ce loss 1.5928410291671753\n",
      "351000 batches processed(0.652844710376883%), ce loss 1.5341250896453857\n",
      "352000 batches processed(0.6547046668167031%), ce loss 1.5233237743377686\n",
      "353000 batches processed(0.6565646232565233%), ce loss 1.4819839000701904\n",
      "354000 batches processed(0.6584245796963435%), ce loss 1.4217474460601807\n",
      "355000 batches processed(0.6602845361361637%), ce loss 1.6240620613098145\n",
      "356000 batches processed(0.6621444925759838%), ce loss 1.2849383354187012\n",
      "357000 batches processed(0.664004449015804%), ce loss 1.3223036527633667\n",
      "358000 batches processed(0.6658644054556242%), ce loss 1.4709537029266357\n",
      "359000 batches processed(0.6677243618954444%), ce loss 1.6999022960662842\n",
      "360000 batches processed(0.6695843183352646%), ce loss 1.5480417013168335\n",
      "361000 batches processed(0.6714442747750847%), ce loss 1.5460381507873535\n",
      "362000 batches processed(0.6733042312149049%), ce loss 1.2915234565734863\n",
      "363000 batches processed(0.6751641876547251%), ce loss 1.4441866874694824\n",
      "364000 batches processed(0.6770241440945453%), ce loss 1.534780740737915\n",
      "365000 batches processed(0.6788841005343654%), ce loss 1.4577765464782715\n",
      "366000 batches processed(0.6807440569741857%), ce loss 1.4470444917678833\n",
      "367000 batches processed(0.6826040134140059%), ce loss 1.282218337059021\n",
      "368000 batches processed(0.6844639698538261%), ce loss 1.4272241592407227\n",
      "369000 batches processed(0.6863239262936462%), ce loss 1.4339977502822876\n",
      "370000 batches processed(0.6881838827334664%), ce loss 1.2541981935501099\n",
      "371000 batches processed(0.6900438391732866%), ce loss 1.6179531812667847\n",
      "372000 batches processed(0.6919037956131068%), ce loss 1.3084396123886108\n",
      "373000 batches processed(0.693763752052927%), ce loss 1.4255359172821045\n",
      "374000 batches processed(0.6956237084927471%), ce loss 1.5213682651519775\n",
      "375000 batches processed(0.6974836649325673%), ce loss 1.4720032215118408\n",
      "376000 batches processed(0.6993436213723875%), ce loss 1.448723316192627\n",
      "377000 batches processed(0.7012035778122077%), ce loss 1.4405256509780884\n",
      "378000 batches processed(0.7030635342520278%), ce loss 1.1528264284133911\n",
      "379000 batches processed(0.704923490691848%), ce loss 1.3013802766799927\n",
      "380000 batches processed(0.7067834471316682%), ce loss 1.5397964715957642\n",
      "381000 batches processed(0.7086434035714884%), ce loss 1.2247799634933472\n",
      "382000 batches processed(0.7105033600113085%), ce loss 1.427854061126709\n",
      "383000 batches processed(0.7123633164511287%), ce loss 1.2922461032867432\n",
      "384000 batches processed(0.7142232728909489%), ce loss 1.3222302198410034\n",
      "385000 batches processed(0.7160832293307691%), ce loss 1.390010952949524\n",
      "386000 batches processed(0.7179431857705892%), ce loss 1.2768478393554688\n",
      "387000 batches processed(0.7198031422104094%), ce loss 1.4042716026306152\n",
      "388000 batches processed(0.7216630986502296%), ce loss 1.391859769821167\n",
      "389000 batches processed(0.7235230550900498%), ce loss 1.4002108573913574\n",
      "390000 batches processed(0.72538301152987%), ce loss 1.3297125101089478\n",
      "391000 batches processed(0.7272429679696901%), ce loss 1.4657596349716187\n",
      "392000 batches processed(0.7291029244095103%), ce loss 1.638822317123413\n",
      "393000 batches processed(0.7309628808493305%), ce loss 1.3999911546707153\n",
      "394000 batches processed(0.7328228372891507%), ce loss 1.3778554201126099\n",
      "395000 batches processed(0.7346827937289708%), ce loss 1.3138247728347778\n",
      "396000 batches processed(0.736542750168791%), ce loss 1.531419038772583\n",
      "397000 batches processed(0.7384027066086112%), ce loss 1.4154174327850342\n",
      "398000 batches processed(0.7402626630484314%), ce loss 1.228469729423523\n",
      "399000 batches processed(0.7421226194882515%), ce loss 1.409700870513916\n",
      "400000 batches processed(0.7439825759280717%), ce loss 1.2549420595169067\n",
      "401000 batches processed(0.745842532367892%), ce loss 1.5286026000976562\n",
      "402000 batches processed(0.7477024888077122%), ce loss 1.5015002489089966\n",
      "403000 batches processed(0.7495624452475323%), ce loss 1.4917078018188477\n",
      "404000 batches processed(0.7514224016873525%), ce loss 1.5178344249725342\n",
      "405000 batches processed(0.7532823581271727%), ce loss 1.1923844814300537\n",
      "406000 batches processed(0.7551423145669929%), ce loss 1.7048919200897217\n",
      "407000 batches processed(0.757002271006813%), ce loss 1.3671157360076904\n",
      "408000 batches processed(0.7588622274466332%), ce loss 1.2659428119659424\n",
      "409000 batches processed(0.7607221838864534%), ce loss 1.296393632888794\n",
      "410000 batches processed(0.7625821403262736%), ce loss 1.2968261241912842\n",
      "411000 batches processed(0.7644420967660938%), ce loss 1.2587660551071167\n",
      "412000 batches processed(0.7663020532059139%), ce loss 1.5647794008255005\n",
      "413000 batches processed(0.7681620096457341%), ce loss 1.3389157056808472\n",
      "414000 batches processed(0.7700219660855543%), ce loss 1.4984475374221802\n",
      "415000 batches processed(0.7718819225253745%), ce loss 1.4866440296173096\n",
      "416000 batches processed(0.7737418789651946%), ce loss 1.389472484588623\n",
      "417000 batches processed(0.7756018354050148%), ce loss 1.3823856115341187\n",
      "418000 batches processed(0.777461791844835%), ce loss 1.6279373168945312\n",
      "419000 batches processed(0.7793217482846552%), ce loss 1.5334664583206177\n",
      "420000 batches processed(0.7811817047244753%), ce loss 1.4720895290374756\n",
      "421000 batches processed(0.7830416611642955%), ce loss 1.1550177335739136\n",
      "422000 batches processed(0.7849016176041157%), ce loss 1.297379732131958\n",
      "423000 batches processed(0.7867615740439359%), ce loss 1.4159845113754272\n",
      "424000 batches processed(0.788621530483756%), ce loss 1.46260404586792\n",
      "425000 batches processed(0.7904814869235762%), ce loss 1.3737624883651733\n",
      "426000 batches processed(0.7923414433633964%), ce loss 1.4379560947418213\n",
      "427000 batches processed(0.7942013998032166%), ce loss 1.4078747034072876\n",
      "428000 batches processed(0.7960613562430368%), ce loss 1.2699718475341797\n",
      "429000 batches processed(0.7979213126828569%), ce loss 1.6151671409606934\n",
      "430000 batches processed(0.7997812691226771%), ce loss 1.6511746644973755\n",
      "431000 batches processed(0.8016412255624973%), ce loss 1.3123176097869873\n",
      "432000 batches processed(0.8035011820023175%), ce loss 1.3730883598327637\n",
      "433000 batches processed(0.8053611384421376%), ce loss 1.313340425491333\n",
      "434000 batches processed(0.8072210948819578%), ce loss 1.5063292980194092\n",
      "435000 batches processed(0.809081051321778%), ce loss 1.720574975013733\n",
      "436000 batches processed(0.8109410077615983%), ce loss 1.4238598346710205\n",
      "437000 batches processed(0.8128009642014185%), ce loss 1.5429284572601318\n",
      "438000 batches processed(0.8146609206412386%), ce loss 1.1933284997940063\n",
      "439000 batches processed(0.8165208770810588%), ce loss 1.2807109355926514\n",
      "440000 batches processed(0.818380833520879%), ce loss 1.267653465270996\n",
      "441000 batches processed(0.8202407899606992%), ce loss 1.4590011835098267\n",
      "442000 batches processed(0.8221007464005193%), ce loss 1.404689073562622\n",
      "443000 batches processed(0.8239607028403395%), ce loss 1.511460542678833\n",
      "444000 batches processed(0.8258206592801597%), ce loss 1.2554086446762085\n",
      "445000 batches processed(0.8276806157199799%), ce loss 1.5818692445755005\n",
      "446000 batches processed(0.8295405721598%), ce loss 1.2886865139007568\n",
      "447000 batches processed(0.8314005285996202%), ce loss 1.3735171556472778\n",
      "448000 batches processed(0.8332604850394404%), ce loss 1.5360413789749146\n",
      "449000 batches processed(0.8351204414792606%), ce loss 1.5407649278640747\n",
      "450000 batches processed(0.8369803979190807%), ce loss 1.2634286880493164\n",
      "451000 batches processed(0.8388403543589009%), ce loss 1.3815919160842896\n",
      "452000 batches processed(0.8407003107987211%), ce loss 1.4809833765029907\n",
      "453000 batches processed(0.8425602672385413%), ce loss 1.6186219453811646\n",
      "454000 batches processed(0.8444202236783614%), ce loss 1.5115079879760742\n",
      "455000 batches processed(0.8462801801181816%), ce loss 1.3428927659988403\n",
      "456000 batches processed(0.8481401365580018%), ce loss 1.3404738903045654\n",
      "457000 batches processed(0.850000092997822%), ce loss 1.3662060499191284\n",
      "458000 batches processed(0.8518600494376422%), ce loss 1.3878302574157715\n",
      "459000 batches processed(0.8537200058774623%), ce loss 1.299047589302063\n",
      "460000 batches processed(0.8555799623172825%), ce loss 1.4835405349731445\n",
      "461000 batches processed(0.8574399187571027%), ce loss 1.3977444171905518\n",
      "462000 batches processed(0.8592998751969229%), ce loss 1.345705270767212\n",
      "463000 batches processed(0.861159831636743%), ce loss 1.330960750579834\n",
      "464000 batches processed(0.8630197880765632%), ce loss 1.6351834535598755\n",
      "465000 batches processed(0.8648797445163834%), ce loss 1.397581934928894\n",
      "466000 batches processed(0.8667397009562036%), ce loss 1.2854117155075073\n",
      "467000 batches processed(0.8685996573960237%), ce loss 1.5556552410125732\n",
      "468000 batches processed(0.8704596138358439%), ce loss 1.4419552087783813\n",
      "469000 batches processed(0.8723195702756641%), ce loss 1.5275295972824097\n",
      "470000 batches processed(0.8741795267154844%), ce loss 1.3799673318862915\n",
      "471000 batches processed(0.8760394831553046%), ce loss 1.568153977394104\n",
      "472000 batches processed(0.8778994395951247%), ce loss 1.1106719970703125\n",
      "473000 batches processed(0.8797593960349449%), ce loss 1.1362570524215698\n",
      "474000 batches processed(0.8816193524747651%), ce loss 1.5190367698669434\n",
      "475000 batches processed(0.8834793089145853%), ce loss 1.490404486656189\n",
      "476000 batches processed(0.8853392653544054%), ce loss 1.2783626317977905\n",
      "477000 batches processed(0.8871992217942256%), ce loss 1.4472525119781494\n",
      "478000 batches processed(0.8890591782340458%), ce loss 1.5362170934677124\n",
      "479000 batches processed(0.890919134673866%), ce loss 1.3654570579528809\n",
      "480000 batches processed(0.8927790911136861%), ce loss 1.2911860942840576\n",
      "481000 batches processed(0.8946390475535063%), ce loss 1.2300240993499756\n",
      "482000 batches processed(0.8964990039933265%), ce loss 1.4453997611999512\n",
      "483000 batches processed(0.8983589604331467%), ce loss 1.3838303089141846\n",
      "484000 batches processed(0.9002189168729668%), ce loss 1.2818284034729004\n",
      "485000 batches processed(0.902078873312787%), ce loss 1.4067177772521973\n",
      "486000 batches processed(0.9039388297526072%), ce loss 1.3963879346847534\n",
      "487000 batches processed(0.9057987861924274%), ce loss 1.4167077541351318\n",
      "488000 batches processed(0.9076587426322476%), ce loss 1.4798001050949097\n",
      "489000 batches processed(0.9095186990720677%), ce loss 1.5336755514144897\n",
      "490000 batches processed(0.9113786555118879%), ce loss 1.4679471254348755\n",
      "491000 batches processed(0.9132386119517081%), ce loss 1.3447097539901733\n",
      "492000 batches processed(0.9150985683915283%), ce loss 1.3217560052871704\n",
      "493000 batches processed(0.9169585248313484%), ce loss 1.4379137754440308\n",
      "494000 batches processed(0.9188184812711686%), ce loss 1.473474383354187\n",
      "495000 batches processed(0.9206784377109888%), ce loss 1.5779856443405151\n",
      "496000 batches processed(0.922538394150809%), ce loss 1.5114953517913818\n",
      "497000 batches processed(0.9243983505906291%), ce loss 1.4767358303070068\n",
      "498000 batches processed(0.9262583070304493%), ce loss 1.6617261171340942\n",
      "499000 batches processed(0.9281182634702695%), ce loss 1.2302765846252441\n",
      "500000 batches processed(0.9299782199100897%), ce loss 1.4149832725524902\n",
      "501000 batches processed(0.9318381763499098%), ce loss 1.274895191192627\n",
      "502000 batches processed(0.93369813278973%), ce loss 1.5174473524093628\n",
      "503000 batches processed(0.9355580892295502%), ce loss 1.3145315647125244\n",
      "504000 batches processed(0.9374180456693704%), ce loss 1.677241563796997\n",
      "505000 batches processed(0.9392780021091907%), ce loss 1.5918253660202026\n",
      "506000 batches processed(0.9411379585490108%), ce loss 1.419317364692688\n",
      "507000 batches processed(0.942997914988831%), ce loss 1.260514259338379\n",
      "508000 batches processed(0.9448578714286512%), ce loss 1.555404543876648\n",
      "509000 batches processed(0.9467178278684714%), ce loss 1.3464500904083252\n",
      "510000 batches processed(0.9485777843082915%), ce loss 1.4229947328567505\n",
      "511000 batches processed(0.9504377407481117%), ce loss 1.5136648416519165\n",
      "512000 batches processed(0.9522976971879319%), ce loss 1.2681125402450562\n",
      "513000 batches processed(0.9541576536277521%), ce loss 1.4952048063278198\n",
      "514000 batches processed(0.9560176100675722%), ce loss 1.878199815750122\n",
      "515000 batches processed(0.9578775665073924%), ce loss 1.4872331619262695\n",
      "516000 batches processed(0.9597375229472126%), ce loss 1.5373328924179077\n",
      "517000 batches processed(0.9615974793870328%), ce loss 1.5966023206710815\n",
      "518000 batches processed(0.963457435826853%), ce loss 1.376520037651062\n",
      "519000 batches processed(0.9653173922666731%), ce loss 1.5604982376098633\n",
      "520000 batches processed(0.9671773487064933%), ce loss 1.478521466255188\n",
      "521000 batches processed(0.9690373051463135%), ce loss 1.4458978176116943\n",
      "522000 batches processed(0.9708972615861337%), ce loss 1.6065863370895386\n",
      "523000 batches processed(0.9727572180259538%), ce loss 1.3317193984985352\n",
      "524000 batches processed(0.974617174465774%), ce loss 1.3054531812667847\n",
      "525000 batches processed(0.9764771309055942%), ce loss 1.4080532789230347\n",
      "526000 batches processed(0.9783370873454144%), ce loss 1.3667181730270386\n",
      "527000 batches processed(0.9801970437852345%), ce loss 1.4443848133087158\n",
      "528000 batches processed(0.9820570002250547%), ce loss 1.4026321172714233\n",
      "529000 batches processed(0.9839169566648749%), ce loss 1.2380785942077637\n",
      "530000 batches processed(0.9857769131046951%), ce loss 1.311888575553894\n",
      "531000 batches processed(0.9876368695445152%), ce loss 1.3945434093475342\n",
      "532000 batches processed(0.9894968259843354%), ce loss 1.1825001239776611\n",
      "533000 batches processed(0.9913567824241556%), ce loss 1.3047946691513062\n",
      "534000 batches processed(0.9932167388639758%), ce loss 1.4165736436843872\n",
      "535000 batches processed(0.9950766953037959%), ce loss 1.4284539222717285\n",
      "536000 batches processed(0.9969366517436161%), ce loss 1.466306447982788\n",
      "537000 batches processed(0.9987966081834363%), ce loss 1.2985001802444458\n",
      "After epoch 1, ce loss is 1.3724043369293213\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD, Adam\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# optimizer = SGD(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = SGD(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "num_epoch = 1\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=2, collate_fn=collate_self_supervision, shuffle=True)\n",
    "for k in range(1, num_epoch+1):\n",
    "    print(f'--- epoch {k} ---')\n",
    "    try:\n",
    "        for i, data in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            texts, label = data     # label shape: [batch, seq_len]\n",
    "            pred = model(texts.to(device)) # batch, seq_len, n_tokens\n",
    "            loss = criterion(pred.transpose(1, 2), label.to(device))\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(f'{i} batches processed({i/len(data_loader)}%), ce loss {loss}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}, batch idx {i}, epoch idx {k}\")\n",
    "\n",
    "    print(f\"After epoch {k}, ce loss is {loss}\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    After training:\n",
      "    prompt: to be or not to be\n",
      "    next seq:  in their pitions death?then be surelymort so  it shall. this is pomarier women;ttelling cannot do yeard andthe criever honour'd frionceallay,to take much; for he is but a ijeldy?etermy form,to distre\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# prompt = 'Barack Obama was born in Honolulu, Hawaii. He was born in'\n",
    "prompt = 'to be or not to be'\n",
    "print(\n",
    "    f\"\"\"\n",
    "    After training:\n",
    "    prompt: {prompt}\n",
    "    next seq: {generate(prompt, model, length=200, temperature=0.8)}\n",
    "    \"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
